diff --git a/old_product.java b/new_product.java
index 80156b2..cad00f7 100644
--- a/old_product.java
+++ b/new_product.java
@@ -6,37 +6,7 @@ public <K, O extends Serializable, S extends Serializable> RecommendationModel<O
             new RecommendationDatasetDataBuilder<>(),
             trainerEnvironment
         )) {
-            // Collect total set of objects and subjects (their identifiers).
-            Set<O> objects = dataset.compute(RecommendationDatasetData::getObjects, RecommendationTrainer::join);
-            Set<S> subjects = dataset.compute(RecommendationDatasetData::getSubjects, RecommendationTrainer::join);
-
-            // Generate initial model (object and subject matrices) initializing them with random values.
-            Map<O, Vector> objMatrix = generateRandomVectorForEach(objects, trainerEnvironment.randomNumbersGenerator());
-            Map<S, Vector> subjMatrix = generateRandomVectorForEach(subjects, trainerEnvironment.randomNumbersGenerator());
-
-            // SGD steps.
-            // TODO: GG-22916 Add convergence check into recommendation system SGD
-            for (int i = 0; i < maxIterations; i++) {
-                int seed = i;
-
-                // Calculate gradient on reach partition and aggregate results.
-                MatrixFactorizationGradient<O, S> grad = dataset.compute(
-                    (data, env) -> data.calculateGradient(
-                        objMatrix,
-                        subjMatrix,
-                        batchSize,
-                        seed ^ env.partition(),
-                        regParam,
-                        learningRate
-                    ),
-                    RecommendationTrainer::sum
-                );
-
-                // Apply aggregated gradient.
-                grad.applyGradient(objMatrix, subjMatrix);
-            }
-
-            return new RecommendationModel<>(objMatrix, subjMatrix);
+            return train(dataset);
         }
         catch (Exception e) {
             throw new RuntimeException(e);
