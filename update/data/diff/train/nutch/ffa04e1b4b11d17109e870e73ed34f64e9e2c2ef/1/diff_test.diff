diff --git a/old_test.java b/new_test.java
index 6f97da6..4415957 100644
--- a/old_test.java
+++ b/new_test.java
@@ -1,15 +1,26 @@
 @Test
   public void testFetch() throws Exception {
 
+    String batchId = "1234";
+    conf.set(GeneratorJob.BATCH_ID, batchId);
+
     // generate seedlist
+    ArrayList<String> normalUrls = new ArrayList<String>();
+    ArrayList<String> sitemapUrls = new ArrayList<String>();
     ArrayList<String> urls = new ArrayList<String>();
 
-    addUrl(urls, "index.html");
-    addUrl(urls, "pagea.html");
-    addUrl(urls, "pageb.html");
-    addUrl(urls, "dup_of_pagea.html");
-    addUrl(urls, "nested_spider_trap.html");
-    addUrl(urls, "exception.html");
+    addUrl(normalUrls, "index.html");
+    addUrl(normalUrls, "pagea.html");
+    addUrl(normalUrls, "pageb.html");
+    addUrl(normalUrls, "dup_of_pagea.html");
+    addUrl(normalUrls, "nested_spider_trap.html");
+    addUrl(normalUrls, "exception.html");
+    addUrl(sitemapUrls, "sitemap1.xml\t-sitemap");
+    addUrl(sitemapUrls, "sitemap2.xml\t-sitemap");
+    addUrl(sitemapUrls, "sitemapIndex.xml\t-sitemap");
+
+    urls.addAll(normalUrls);
+    urls.addAll(sitemapUrls);
 
     CrawlTestUtil.generateSeedList(fs, urlPath, urls);
 
@@ -20,7 +31,10 @@
     // generate
     long time = System.currentTimeMillis();
     GeneratorJob g = new GeneratorJob(conf);
-    String batchId = g.generate(Long.MAX_VALUE, time, false, false);
+    //  generate for non sitemap
+    g.generate(Long.MAX_VALUE, time, false, false, false);
+    //    generate for only sitemap
+    g.generate(Long.MAX_VALUE, time, false, false, true);
 
     // fetch
     time = System.currentTimeMillis();
@@ -37,7 +51,7 @@
 
     List<URLWebPage> pages = CrawlTestUtil.readContents(webPageStore,
         Mark.FETCH_MARK, (String[]) null);
-    assertEquals(urls.size(), pages.size());
+    assertEquals(normalUrls.size(), pages.size());
     List<String> handledurls = new ArrayList<String>();
     for (URLWebPage up : pages) {
       ByteBuffer bb = up.getDatum().getContent();
@@ -49,13 +63,13 @@
         handledurls.add(up.getUrl());
       }
     }
-    Collections.sort(urls);
+    Collections.sort(normalUrls);
     Collections.sort(handledurls);
 
     // verify that enough pages were handled
-    assertEquals(urls.size(), handledurls.size());
+    assertEquals(normalUrls.size(), handledurls.size());
 
     // verify that correct pages were handled
-    assertTrue(handledurls.containsAll(urls));
-    assertTrue(urls.containsAll(handledurls));
+    assertTrue(handledurls.containsAll(normalUrls));
+    assertTrue(normalUrls.containsAll(handledurls));
   }
\ No newline at end of file
