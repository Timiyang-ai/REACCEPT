--------------------------------------------------------------------------------------------------------------------------------
new state
3
----------------------------------------------------------------
new description
测试通过，覆盖率：0.0
----------------------------------------------------------------
new message

--------------------------------------------------------------------------------------------------------------------------------
old state
3
----------------------------------------------------------------
old description
测试通过，覆盖率：0.0
----------------------------------------------------------------
old message

--------------------------------------------------------------------------------------------------------------------------------
old product
private <ML extends AbstractClassifier, FS extends AbstractFeatureSelector> void trainAndValidate(
            Class<ML> modelerClass, 
            ML.AbstractTrainingParameters modelerTrainingParameters,
            Class<FS> featureSelectorClass, 
            FS.AbstractTrainingParameters featureSelectorTrainingParameters,
            double expectedF1score) {
        Configuration conf = Configuration.getConfiguration();
        
        
        String dbName = this.getClass().getSimpleName();
        
        Map<Object, URI> dataset = new HashMap<>();
        try {
            dataset.put("negative", this.getClass().getClassLoader().getResource("datasets/sentimentAnalysis.neg.txt").toURI());
            dataset.put("positive", this.getClass().getClassLoader().getResource("datasets/sentimentAnalysis.pos.txt").toURI());
        }
        catch(UncheckedIOException | URISyntaxException ex) {
            logger.warn("Unable to download datasets, skipping test.");
            throw new RuntimeException(ex);
        }

        TextClassifier.TrainingParameters trainingParameters = new TextClassifier.TrainingParameters();
        
        //Classifier configuration
        trainingParameters.setModelerTrainingParameters(modelerTrainingParameters);
        
        //data transfomation configuration
        trainingParameters.setDataTransformerTrainingParameters(null);
        
        //feature selection configuration
        trainingParameters.setFeatureSelectorTrainingParameters(featureSelectorTrainingParameters);
        
        //text extraction configuration
        NgramsExtractor.Parameters exParams = new NgramsExtractor.Parameters();
        exParams.setMaxDistanceBetweenKwds(2);
        exParams.setExaminationWindowLength(6);
        trainingParameters.setTextExtractorParameters(exParams);

        TextClassifier instance = new TextClassifier(dbName, conf, trainingParameters);
        instance.fit(dataset);


        ClassificationMetrics vm = instance.validate(dataset);
        assertEquals(expectedF1score, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH);

        instance.close();
        //instance = null;
        
        
        
        instance = new TextClassifier(dbName, conf);
        Dataframe validationData = null;
        try {
            validationData = instance.predict(this.getClass().getClassLoader().getResource("datasets/sentimentAnalysis.unlabelled.txt").toURI());
        }
        catch(UncheckedIOException | URISyntaxException ex) {
            logger.warn("Unable to download datasets, skipping test.");
            throw new RuntimeException(ex);
        }
        
        List<Object> expResult = Arrays.asList("negative","positive");
        int i = 0;
        for(Record r : validationData.values()) {
            assertEquals(expResult.get(i), r.getYPredicted());
            ++i;
        }
        
        instance.delete();
        validationData.delete();
    }
----------------------------------------------------------------
old test
@Test
    public void testTrainAndValidate() {
        logger.info("testTrainAndValidate");
        
        Configuration conf = Configuration.getConfiguration();
        
        Dataframe[] data = Datasets.carsNumeric(conf);
        Dataframe trainingData = data[0];
        
        Dataframe validationData = data[1];
        
        
        String dbName = this.getClass().getSimpleName();

        Modeler.TrainingParameters trainingParameters = new Modeler.TrainingParameters();
        
        
        //Model Configuration

        MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters();
        modelTrainingParameters.setMultiProbabilityWeighted(true);
        trainingParameters.setModelerTrainingParameters(modelTrainingParameters);

        //data transfomation configuration
        DummyXMinMaxNormalizer.TrainingParameters dtParams = new DummyXMinMaxNormalizer.TrainingParameters();
        trainingParameters.setDataTransformerTrainingParameters(dtParams);
        
        //feature selection configuration
        trainingParameters.setFeatureSelectorTrainingParameters(null);

        Modeler instance = new Modeler(dbName, conf, trainingParameters);
        instance.fit(trainingData);

        instance.close();

        instance = new Modeler(dbName, conf);

        instance.predict(trainingData);

        ClassificationMetrics vm = new ClassificationMetrics(trainingData);

        double expResult2 = 0.8;
        assertEquals(expResult2, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH);

        instance.close();
        //instance = null;


        instance = new Modeler(dbName, conf);
        
        instance.predict(validationData);
        
        
        
        Map<Integer, Object> expResult = new HashMap<>();
        Map<Integer, Object> result = new HashMap<>();
        for(Map.Entry<Integer, Record> e : validationData.entries()) {
            Integer rId = e.getKey();
            Record r = e.getValue();
            expResult.put(rId, r.getY());
            result.put(rId, r.getYPredicted());
        }
        assertEquals(expResult, result);
        
        instance.delete();
        
        trainingData.delete();
        validationData.delete();
    }
----------------------------------------------------------------
new product
private <ML extends AbstractClassifier, FS extends AbstractFeatureSelector> void trainAndValidate(
            Class<ML> modelerClass, 
            ML.AbstractTrainingParameters modelerTrainingParameters,
            Class<FS> featureSelectorClass, 
            FS.AbstractTrainingParameters featureSelectorTrainingParameters,
            double expectedF1score) {
        Configuration conf = Configuration.getConfiguration();
        
        
        String dbName = this.getClass().getSimpleName();
        
        Map<Object, URI> dataset = new HashMap<>();
        try {
            dataset.put("negative", this.getClass().getClassLoader().getResource("datasets/sentimentAnalysis.neg.txt").toURI());
            dataset.put("positive", this.getClass().getClassLoader().getResource("datasets/sentimentAnalysis.pos.txt").toURI());
        }
        catch(UncheckedIOException | URISyntaxException ex) {
            logger.warn("Unable to download datasets, skipping test.");
            throw new RuntimeException(ex);
        }

        TextClassifier.TrainingParameters trainingParameters = new TextClassifier.TrainingParameters();
        
        //Classifier configuration
        trainingParameters.setModelerTrainingParameters(modelerTrainingParameters);
        
        //data transfomation configuration
        trainingParameters.setDataTransformerTrainingParameters(null);
        
        //feature selection configuration
        trainingParameters.setFeatureSelectorTrainingParameters(featureSelectorTrainingParameters);
        
        //text extraction configuration
        NgramsExtractor.Parameters exParams = new NgramsExtractor.Parameters();
        exParams.setMaxDistanceBetweenKwds(2);
        exParams.setExaminationWindowLength(6);
        trainingParameters.setTextExtractorParameters(exParams);

        TextClassifier instance = MLBuilder.create(trainingParameters, dbName, conf);
        instance.fit(dataset);


        ClassificationMetrics vm = instance.validate(dataset);
        assertEquals(expectedF1score, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH);

        instance.close();
        //instance = null;
        
        
        
        instance = MLBuilder.load(TextClassifier.class, dbName, conf);
        Dataframe validationData = null;
        try {
            validationData = instance.predict(this.getClass().getClassLoader().getResource("datasets/sentimentAnalysis.unlabelled.txt").toURI());
        }
        catch(UncheckedIOException | URISyntaxException ex) {
            logger.warn("Unable to download datasets, skipping test.");
            throw new RuntimeException(ex);
        }
        
        List<Object> expResult = Arrays.asList("negative","positive");
        int i = 0;
        for(Record r : validationData.values()) {
            assertEquals(expResult.get(i), r.getYPredicted());
            ++i;
        }
        
        instance.delete();
        validationData.delete();
    }
----------------------------------------------------------------
new test
@Test
    public void testTrainAndValidate() {
        logger.info("testTrainAndValidate");
        
        Configuration conf = Configuration.getConfiguration();
        
        Dataframe[] data = Datasets.carsNumeric(conf);
        Dataframe trainingData = data[0];
        
        Dataframe validationData = data[1];
        
        
        String dbName = this.getClass().getSimpleName();

        Modeler.TrainingParameters trainingParameters = new Modeler.TrainingParameters();
        
        
        //Model Configuration

        MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters();
        modelTrainingParameters.setMultiProbabilityWeighted(true);
        trainingParameters.setModelerTrainingParameters(modelTrainingParameters);

        //data transfomation configuration
        DummyXMinMaxNormalizer.TrainingParameters dtParams = new DummyXMinMaxNormalizer.TrainingParameters();
        trainingParameters.setDataTransformerTrainingParameters(dtParams);
        
        //feature selection configuration
        trainingParameters.setFeatureSelectorTrainingParameters(null);

        Modeler instance = MLBuilder.create(trainingParameters, dbName, conf);
        instance.fit(trainingData);

        instance.close();

        instance = MLBuilder.load(Modeler.class, dbName, conf);

        instance.predict(trainingData);

        ClassificationMetrics vm = new ClassificationMetrics(trainingData);

        double expResult2 = 0.8;
        assertEquals(expResult2, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH);

        instance.close();
        //instance = null;


        instance = MLBuilder.load(Modeler.class, dbName, conf);
        
        instance.predict(validationData);
        
        
        
        Map<Integer, Object> expResult = new HashMap<>();
        Map<Integer, Object> result = new HashMap<>();
        for(Map.Entry<Integer, Record> e : validationData.entries()) {
            Integer rId = e.getKey();
            Record r = e.getValue();
            expResult.put(rId, r.getY());
            result.put(rId, r.getYPredicted());
        }
        assertEquals(expResult, result);
        
        instance.delete();
        
        trainingData.delete();
        validationData.delete();
    }
----------------------------------------------------------------
diff product
diff --git a/old_product.java b/new_product.java
index 55b8324..b8bd0ee 100644
--- a/old_product.java
+++ b/new_product.java
@@ -36,7 +36,7 @@ private <ML extends AbstractClassifier, FS extends AbstractFeatureSelector> void
         exParams.setExaminationWindowLength(6);
         trainingParameters.setTextExtractorParameters(exParams);
 
-        TextClassifier instance = new TextClassifier(dbName, conf, trainingParameters);
+        TextClassifier instance = MLBuilder.create(trainingParameters, dbName, conf);
         instance.fit(dataset);
 
 
@@ -48,7 +48,7 @@ private <ML extends AbstractClassifier, FS extends AbstractFeatureSelector> void
         
         
         
-        instance = new TextClassifier(dbName, conf);
+        instance = MLBuilder.load(TextClassifier.class, dbName, conf);
         Dataframe validationData = null;
         try {
             validationData = instance.predict(this.getClass().getClassLoader().getResource("datasets/sentimentAnalysis.unlabelled.txt").toURI());

----------------------------------------------------------------
diff test
diff --git a/old_test.java b/new_test.java
index d6448b8..ed181da 100644
--- a/old_test.java
+++ b/new_test.java
@@ -28,12 +28,12 @@
         //feature selection configuration
         trainingParameters.setFeatureSelectorTrainingParameters(null);
 
-        Modeler instance = new Modeler(dbName, conf, trainingParameters);
+        Modeler instance = MLBuilder.create(trainingParameters, dbName, conf);
         instance.fit(trainingData);
 
         instance.close();
 
-        instance = new Modeler(dbName, conf);
+        instance = MLBuilder.load(Modeler.class, dbName, conf);
 
         instance.predict(trainingData);
 
@@ -46,7 +46,7 @@
         //instance = null;
 
 
-        instance = new Modeler(dbName, conf);
+        instance = MLBuilder.load(Modeler.class, dbName, conf);
         
         instance.predict(validationData);
         

--------------------------------------------------------------------------------------------------------------------------------
sample diff product
diff --git a/old_product.java b/new_product.java
index 48730e6..4dc1993 100644
--- a/old_product.java
+++ b/new_product.java
@@ -2,7 +2,7 @@ private <ML extends AbstractClassifier, FS extends AbstractFeatureSelector> void
             ML.AbstractTrainingParameters modelerTrainingParameters,
             FS.AbstractTrainingParameters featureSelectorTrainingParameters,
             double expectedF1score) {
-        Configuration conf = Configuration.getConfiguration();
+        Configuration configuration = Configuration.getConfiguration();
         
         
         String storageName = this.getClass().getSimpleName();
@@ -34,7 +34,7 @@ private <ML extends AbstractClassifier, FS extends AbstractFeatureSelector> void
         exParams.setExaminationWindowLength(6);
         trainingParameters.setTextExtractorParameters(exParams);
 
-        TextClassifier instance = MLBuilder.create(trainingParameters, conf);
+        TextClassifier instance = MLBuilder.create(trainingParameters, configuration);
         instance.fit(dataset);
         instance.save(storageName);
 
@@ -47,7 +47,7 @@ private <ML extends AbstractClassifier, FS extends AbstractFeatureSelector> void
         
         
         
-        instance = MLBuilder.load(TextClassifier.class, storageName, conf);
+        instance = MLBuilder.load(TextClassifier.class, storageName, configuration);
         Dataframe validationData;
         try {
             validationData = instance.predict(this.getClass().getClassLoader().getResource("datasets/sentimentAnalysis.unlabelled.txt").toURI());

----------------------------------------------------------------
sample diff test
diff --git a/old_test.java b/new_test.java
index e5d7d84..bc7f05a 100644
--- a/old_test.java
+++ b/new_test.java
@@ -2,9 +2,9 @@
     public void testTrainAndValidate() {
         logger.info("testTrainAndValidate");
         
-        Configuration conf = Configuration.getConfiguration();
+        Configuration configuration = Configuration.getConfiguration();
         
-        Dataframe[] data = Datasets.carsNumeric(conf);
+        Dataframe[] data = Datasets.carsNumeric(configuration);
         Dataframe trainingData = data[0];
         
         Dataframe validationData = data[1];
@@ -28,13 +28,13 @@
         //feature selection configuration
         trainingParameters.setFeatureSelectorTrainingParameters(null);
 
-        Modeler instance = MLBuilder.create(trainingParameters, conf);
+        Modeler instance = MLBuilder.create(trainingParameters, configuration);
         instance.fit(trainingData);
         instance.save(storageName);
 
         instance.close();
 
-        instance = MLBuilder.load(Modeler.class, storageName, conf);
+        instance = MLBuilder.load(Modeler.class, storageName, configuration);
 
         instance.predict(trainingData);
 
@@ -48,7 +48,7 @@
         //instance = null;
 
 
-        instance = MLBuilder.load(Modeler.class, storageName, conf);
+        instance = MLBuilder.load(Modeler.class, storageName, configuration);
         
         instance.predict(validationData);
         

----------------------------------------------------------------
coverage
0.0
--------------------------------------------------------------------------------------------------------------------------------
当前次数：1
----------------------------------------------------------------
LLM输出
<new_test>
@Test
public void testTrainAndValidate() {
    logger.info("testTrainAndValidate");
    
    Configuration configuration = Configuration.getConfiguration();
    
    Dataframe[] data = Datasets.carsNumeric(configuration);
    Dataframe trainingData = data[0];
    
    Dataframe validationData = data[1];
    
    String dbName = this.getClass().getSimpleName();

    Modeler.TrainingParameters trainingParameters = new Modeler.TrainingParameters();
    
    // Model Configuration
    MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters();
    modelTrainingParameters.setMultiProbabilityWeighted(true);
    trainingParameters.setModelerTrainingParameters(modelTrainingParameters);

    // Data transformation configuration
    DummyXMinMaxNormalizer.TrainingParameters dtParams = new DummyXMinMaxNormalizer.TrainingParameters();
    trainingParameters.setDataTransformerTrainingParameters(dtParams);
    
    // Feature selection configuration
    trainingParameters.setFeatureSelectorTrainingParameters(null);

    Modeler instance = MLBuilder.create(trainingParameters, dbName, configuration);
    instance.fit(trainingData);

    instance.close();

    instance = MLBuilder.load(Modeler.class, dbName, configuration);

    instance.predict(trainingData);

    ClassificationMetrics vm = new ClassificationMetrics(trainingData);

    double expResult2 = 0.8;
    assertEquals(expResult2, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH);

    instance.close();

    instance = MLBuilder.load(Modeler.class, dbName, configuration);
    
    instance.predict(validationData);
    
    Map<Integer, Object> expResult = new HashMap<>();
    Map<Integer, Object> result = new HashMap<>();
    for (Map.Entry<Integer, Record> e : validationData.entries()) {
        Integer rId = e.getKey();
        Record r = e.getValue();
        expResult.put(rId, r.getY());
        result.put(rId, r.getYPredicted());
    }
    assertEquals(expResult, result);
    
    instance.delete();
    
    trainingData.delete();
    validationData.delete();
}
</new_test>
----------------------------------------------------------------
测试代码

@Test
public void testTrainAndValidate() {
    logger.info("testTrainAndValidate");
    
    Configuration configuration = Configuration.getConfiguration();
    
    Dataframe[] data = Datasets.carsNumeric(configuration);
    Dataframe trainingData = data[0];
    
    Dataframe validationData = data[1];
    
    String dbName = this.getClass().getSimpleName();

    Modeler.TrainingParameters trainingParameters = new Modeler.TrainingParameters();
    
    // Model Configuration
    MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters();
    modelTrainingParameters.setMultiProbabilityWeighted(true);
    trainingParameters.setModelerTrainingParameters(modelTrainingParameters);

    // Data transformation configuration
    DummyXMinMaxNormalizer.TrainingParameters dtParams = new DummyXMinMaxNormalizer.TrainingParameters();
    trainingParameters.setDataTransformerTrainingParameters(dtParams);
    
    // Feature selection configuration
    trainingParameters.setFeatureSelectorTrainingParameters(null);

    Modeler instance = MLBuilder.create(trainingParameters, dbName, configuration);
    instance.fit(trainingData);

    instance.close();

    instance = MLBuilder.load(Modeler.class, dbName, configuration);

    instance.predict(trainingData);

    ClassificationMetrics vm = new ClassificationMetrics(trainingData);

    double expResult2 = 0.8;
    assertEquals(expResult2, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH);

    instance.close();

    instance = MLBuilder.load(Modeler.class, dbName, configuration);
    
    instance.predict(validationData);
    
    Map<Integer, Object> expResult = new HashMap<>();
    Map<Integer, Object> result = new HashMap<>();
    for (Map.Entry<Integer, Record> e : validationData.entries()) {
        Integer rId = e.getKey();
        Record r = e.getValue();
        expResult.put(rId, r.getY());
        result.put(rId, r.getYPredicted());
    }
    assertEquals(expResult, result);
    
    instance.delete();
    
    trainingData.delete();
    validationData.delete();
}

----------------------------------------------------------------
改动
--- 

+++ 

@@ -1,69 +1,64 @@

+
 @Test
-    public void testTrainAndValidate() {
-        logger.info("testTrainAndValidate");
-        
-        Configuration conf = Configuration.getConfiguration();
-        
-        Dataframe[] data = Datasets.carsNumeric(conf);
-        Dataframe trainingData = data[0];
-        
-        Dataframe validationData = data[1];
-        
-        
-        String dbName = this.getClass().getSimpleName();
+public void testTrainAndValidate() {
+    logger.info("testTrainAndValidate");
+    
+    Configuration configuration = Configuration.getConfiguration();
+    
+    Dataframe[] data = Datasets.carsNumeric(configuration);
+    Dataframe trainingData = data[0];
+    
+    Dataframe validationData = data[1];
+    
+    String dbName = this.getClass().getSimpleName();
 
-        Modeler.TrainingParameters trainingParameters = new Modeler.TrainingParameters();
-        
-        
-        //Model Configuration
+    Modeler.TrainingParameters trainingParameters = new Modeler.TrainingParameters();
+    
+    // Model Configuration
+    MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters();
+    modelTrainingParameters.setMultiProbabilityWeighted(true);
+    trainingParameters.setModelerTrainingParameters(modelTrainingParameters);
 
-        MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters();
-        modelTrainingParameters.setMultiProbabilityWeighted(true);
-        trainingParameters.setModelerTrainingParameters(modelTrainingParameters);
+    // Data transformation configuration
+    DummyXMinMaxNormalizer.TrainingParameters dtParams = new DummyXMinMaxNormalizer.TrainingParameters();
+    trainingParameters.setDataTransformerTrainingParameters(dtParams);
+    
+    // Feature selection configuration
+    trainingParameters.setFeatureSelectorTrainingParameters(null);
 
-        //data transfomation configuration
-        DummyXMinMaxNormalizer.TrainingParameters dtParams = new DummyXMinMaxNormalizer.TrainingParameters();
-        trainingParameters.setDataTransformerTrainingParameters(dtParams);
-        
-        //feature selection configuration
-        trainingParameters.setFeatureSelectorTrainingParameters(null);
+    Modeler instance = MLBuilder.create(trainingParameters, dbName, configuration);
+    instance.fit(trainingData);
 
-        Modeler instance = new Modeler(dbName, conf, trainingParameters);
-        instance.fit(trainingData);
+    instance.close();
 
-        instance.close();
+    instance = MLBuilder.load(Modeler.class, dbName, configuration);
 
-        instance = new Modeler(dbName, conf);
+    instance.predict(trainingData);
 
-        instance.predict(trainingData);
+    ClassificationMetrics vm = new ClassificationMetrics(trainingData);
 
-        ClassificationMetrics vm = new ClassificationMetrics(trainingData);
+    double expResult2 = 0.8;
+    assertEquals(expResult2, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH);
 
-        double expResult2 = 0.8;
-        assertEquals(expResult2, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH);
+    instance.close();
 
-        instance.close();
-        //instance = null;
+    instance = MLBuilder.load(Modeler.class, dbName, configuration);
+    
+    instance.predict(validationData);
+    
+    Map<Integer, Object> expResult = new HashMap<>();
+    Map<Integer, Object> result = new HashMap<>();
+    for (Map.Entry<Integer, Record> e : validationData.entries()) {
+        Integer rId = e.getKey();
+        Record r = e.getValue();
+        expResult.put(rId, r.getY());
+        result.put(rId, r.getYPredicted());
+    }
+    assertEquals(expResult, result);
+    
+    instance.delete();
+    
+    trainingData.delete();
+    validationData.delete();
+}
 
-
-        instance = new Modeler(dbName, conf);
-        
-        instance.predict(validationData);
-        
-        
-        
-        Map<Integer, Object> expResult = new HashMap<>();
-        Map<Integer, Object> result = new HashMap<>();
-        for(Map.Entry<Integer, Record> e : validationData.entries()) {
-            Integer rId = e.getKey();
-            Record r = e.getValue();
-            expResult.put(rId, r.getY());
-            result.put(rId, r.getYPredicted());
-        }
-        assertEquals(expResult, result);
-        
-        instance.delete();
-        
-        trainingData.delete();
-        validationData.delete();
-    }

----------------------------------------------------------------
state
3
----------------------------------------------------------------
description
测试通过，覆盖率：0.0
----------------------------------------------------------------
message

--------------------------------------------------------------------------------------------------------------------------------
总次数：1
----------------------------------------------------------------
generated test

@Test
public void testTrainAndValidate() {
    logger.info("testTrainAndValidate");
    
    Configuration configuration = Configuration.getConfiguration();
    
    Dataframe[] data = Datasets.carsNumeric(configuration);
    Dataframe trainingData = data[0];
    
    Dataframe validationData = data[1];
    
    String dbName = this.getClass().getSimpleName();

    Modeler.TrainingParameters trainingParameters = new Modeler.TrainingParameters();
    
    // Model Configuration
    MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters();
    modelTrainingParameters.setMultiProbabilityWeighted(true);
    trainingParameters.setModelerTrainingParameters(modelTrainingParameters);

    // Data transformation configuration
    DummyXMinMaxNormalizer.TrainingParameters dtParams = new DummyXMinMaxNormalizer.TrainingParameters();
    trainingParameters.setDataTransformerTrainingParameters(dtParams);
    
    // Feature selection configuration
    trainingParameters.setFeatureSelectorTrainingParameters(null);

    Modeler instance = MLBuilder.create(trainingParameters, dbName, configuration);
    instance.fit(trainingData);

    instance.close();

    instance = MLBuilder.load(Modeler.class, dbName, configuration);

    instance.predict(trainingData);

    ClassificationMetrics vm = new ClassificationMetrics(trainingData);

    double expResult2 = 0.8;
    assertEquals(expResult2, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH);

    instance.close();

    instance = MLBuilder.load(Modeler.class, dbName, configuration);
    
    instance.predict(validationData);
    
    Map<Integer, Object> expResult = new HashMap<>();
    Map<Integer, Object> result = new HashMap<>();
    for (Map.Entry<Integer, Record> e : validationData.entries()) {
        Integer rId = e.getKey();
        Record r = e.getValue();
        expResult.put(rId, r.getY());
        result.put(rId, r.getYPredicted());
    }
    assertEquals(expResult, result);
    
    instance.delete();
    
    trainingData.delete();
    validationData.delete();
}

----------------------------------------------------------------
diff old generated test
--- 

+++ 

@@ -1,69 +1,64 @@

+
 @Test
-    public void testTrainAndValidate() {
-        logger.info("testTrainAndValidate");
-        
-        Configuration conf = Configuration.getConfiguration();
-        
-        Dataframe[] data = Datasets.carsNumeric(conf);
-        Dataframe trainingData = data[0];
-        
-        Dataframe validationData = data[1];
-        
-        
-        String dbName = this.getClass().getSimpleName();
+public void testTrainAndValidate() {
+    logger.info("testTrainAndValidate");
+    
+    Configuration configuration = Configuration.getConfiguration();
+    
+    Dataframe[] data = Datasets.carsNumeric(configuration);
+    Dataframe trainingData = data[0];
+    
+    Dataframe validationData = data[1];
+    
+    String dbName = this.getClass().getSimpleName();
 
-        Modeler.TrainingParameters trainingParameters = new Modeler.TrainingParameters();
-        
-        
-        //Model Configuration
+    Modeler.TrainingParameters trainingParameters = new Modeler.TrainingParameters();
+    
+    // Model Configuration
+    MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters();
+    modelTrainingParameters.setMultiProbabilityWeighted(true);
+    trainingParameters.setModelerTrainingParameters(modelTrainingParameters);
 
-        MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters();
-        modelTrainingParameters.setMultiProbabilityWeighted(true);
-        trainingParameters.setModelerTrainingParameters(modelTrainingParameters);
+    // Data transformation configuration
+    DummyXMinMaxNormalizer.TrainingParameters dtParams = new DummyXMinMaxNormalizer.TrainingParameters();
+    trainingParameters.setDataTransformerTrainingParameters(dtParams);
+    
+    // Feature selection configuration
+    trainingParameters.setFeatureSelectorTrainingParameters(null);
 
-        //data transfomation configuration
-        DummyXMinMaxNormalizer.TrainingParameters dtParams = new DummyXMinMaxNormalizer.TrainingParameters();
-        trainingParameters.setDataTransformerTrainingParameters(dtParams);
-        
-        //feature selection configuration
-        trainingParameters.setFeatureSelectorTrainingParameters(null);
+    Modeler instance = MLBuilder.create(trainingParameters, dbName, configuration);
+    instance.fit(trainingData);
 
-        Modeler instance = new Modeler(dbName, conf, trainingParameters);
-        instance.fit(trainingData);
+    instance.close();
 
-        instance.close();
+    instance = MLBuilder.load(Modeler.class, dbName, configuration);
 
-        instance = new Modeler(dbName, conf);
+    instance.predict(trainingData);
 
-        instance.predict(trainingData);
+    ClassificationMetrics vm = new ClassificationMetrics(trainingData);
 
-        ClassificationMetrics vm = new ClassificationMetrics(trainingData);
+    double expResult2 = 0.8;
+    assertEquals(expResult2, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH);
 
-        double expResult2 = 0.8;
-        assertEquals(expResult2, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH);
+    instance.close();
 
-        instance.close();
-        //instance = null;
+    instance = MLBuilder.load(Modeler.class, dbName, configuration);
+    
+    instance.predict(validationData);
+    
+    Map<Integer, Object> expResult = new HashMap<>();
+    Map<Integer, Object> result = new HashMap<>();
+    for (Map.Entry<Integer, Record> e : validationData.entries()) {
+        Integer rId = e.getKey();
+        Record r = e.getValue();
+        expResult.put(rId, r.getY());
+        result.put(rId, r.getYPredicted());
+    }
+    assertEquals(expResult, result);
+    
+    instance.delete();
+    
+    trainingData.delete();
+    validationData.delete();
+}
 
-
-        instance = new Modeler(dbName, conf);
-        
-        instance.predict(validationData);
-        
-        
-        
-        Map<Integer, Object> expResult = new HashMap<>();
-        Map<Integer, Object> result = new HashMap<>();
-        for(Map.Entry<Integer, Record> e : validationData.entries()) {
-            Integer rId = e.getKey();
-            Record r = e.getValue();
-            expResult.put(rId, r.getY());
-            result.put(rId, r.getYPredicted());
-        }
-        assertEquals(expResult, result);
-        
-        instance.delete();
-        
-        trainingData.delete();
-        validationData.delete();
-    }

----------------------------------------------------------------
diff generated new test
--- 

+++ 

@@ -1,64 +1,69 @@

+@Test
+    public void testTrainAndValidate() {
+        logger.info("testTrainAndValidate");
+        
+        Configuration conf = Configuration.getConfiguration();
+        
+        Dataframe[] data = Datasets.carsNumeric(conf);
+        Dataframe trainingData = data[0];
+        
+        Dataframe validationData = data[1];
+        
+        
+        String dbName = this.getClass().getSimpleName();
 
-@Test
-public void testTrainAndValidate() {
-    logger.info("testTrainAndValidate");
-    
-    Configuration configuration = Configuration.getConfiguration();
-    
-    Dataframe[] data = Datasets.carsNumeric(configuration);
-    Dataframe trainingData = data[0];
-    
-    Dataframe validationData = data[1];
-    
-    String dbName = this.getClass().getSimpleName();
+        Modeler.TrainingParameters trainingParameters = new Modeler.TrainingParameters();
+        
+        
+        //Model Configuration
 
-    Modeler.TrainingParameters trainingParameters = new Modeler.TrainingParameters();
-    
-    // Model Configuration
-    MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters();
-    modelTrainingParameters.setMultiProbabilityWeighted(true);
-    trainingParameters.setModelerTrainingParameters(modelTrainingParameters);
+        MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters();
+        modelTrainingParameters.setMultiProbabilityWeighted(true);
+        trainingParameters.setModelerTrainingParameters(modelTrainingParameters);
 
-    // Data transformation configuration
-    DummyXMinMaxNormalizer.TrainingParameters dtParams = new DummyXMinMaxNormalizer.TrainingParameters();
-    trainingParameters.setDataTransformerTrainingParameters(dtParams);
-    
-    // Feature selection configuration
-    trainingParameters.setFeatureSelectorTrainingParameters(null);
+        //data transfomation configuration
+        DummyXMinMaxNormalizer.TrainingParameters dtParams = new DummyXMinMaxNormalizer.TrainingParameters();
+        trainingParameters.setDataTransformerTrainingParameters(dtParams);
+        
+        //feature selection configuration
+        trainingParameters.setFeatureSelectorTrainingParameters(null);
 
-    Modeler instance = MLBuilder.create(trainingParameters, dbName, configuration);
-    instance.fit(trainingData);
+        Modeler instance = MLBuilder.create(trainingParameters, dbName, conf);
+        instance.fit(trainingData);
 
-    instance.close();
+        instance.close();
 
-    instance = MLBuilder.load(Modeler.class, dbName, configuration);
+        instance = MLBuilder.load(Modeler.class, dbName, conf);
 
-    instance.predict(trainingData);
+        instance.predict(trainingData);
 
-    ClassificationMetrics vm = new ClassificationMetrics(trainingData);
+        ClassificationMetrics vm = new ClassificationMetrics(trainingData);
 
-    double expResult2 = 0.8;
-    assertEquals(expResult2, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH);
+        double expResult2 = 0.8;
+        assertEquals(expResult2, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH);
 
-    instance.close();
+        instance.close();
+        //instance = null;
 
-    instance = MLBuilder.load(Modeler.class, dbName, configuration);
-    
-    instance.predict(validationData);
-    
-    Map<Integer, Object> expResult = new HashMap<>();
-    Map<Integer, Object> result = new HashMap<>();
-    for (Map.Entry<Integer, Record> e : validationData.entries()) {
-        Integer rId = e.getKey();
-        Record r = e.getValue();
-        expResult.put(rId, r.getY());
-        result.put(rId, r.getYPredicted());
+
+        instance = MLBuilder.load(Modeler.class, dbName, conf);
+        
+        instance.predict(validationData);
+        
+        
+        
+        Map<Integer, Object> expResult = new HashMap<>();
+        Map<Integer, Object> result = new HashMap<>();
+        for(Map.Entry<Integer, Record> e : validationData.entries()) {
+            Integer rId = e.getKey();
+            Record r = e.getValue();
+            expResult.put(rId, r.getY());
+            result.put(rId, r.getYPredicted());
+        }
+        assertEquals(expResult, result);
+        
+        instance.delete();
+        
+        trainingData.delete();
+        validationData.delete();
     }
-    assertEquals(expResult, result);
-    
-    instance.delete();
-    
-    trainingData.delete();
-    validationData.delete();
-}
-

--------------------------------------------------------------------------------------------------------------------------------
