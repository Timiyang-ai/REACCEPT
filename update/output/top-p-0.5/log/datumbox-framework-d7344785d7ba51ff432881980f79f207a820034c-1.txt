--------------------------------------------------------------------------------------------------------------------------------
new state
3
----------------------------------------------------------------
new description
测试通过，覆盖率：0.0
----------------------------------------------------------------
new message

--------------------------------------------------------------------------------------------------------------------------------
old state
0
----------------------------------------------------------------
old description
编译报错
----------------------------------------------------------------
old message
COMPILATION ERROR : 
/E:/1/datumbox-framework/datumbox-framework-applications/src/test/java/com/datumbox/framework/applications/datamodeling/ModelerTest.java:[70,31] 程序包DummyXMinMaxNormalizer不存在
/E:/1/datumbox-framework/datumbox-framework-applications/src/test/java/com/datumbox/framework/applications/datamodeling/ModelerTest.java:[70,88] 程序包DummyXMinMaxNormalizer不存在
Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.6.0:testCompile (default-testCompile) on project datumbox-framework-applications: Compilation failure: Compilation failure:
/E:/1/datumbox-framework/datumbox-framework-applications/src/test/java/com/datumbox/framework/applications/datamodeling/ModelerTest.java:[70,31] 程序包DummyXMinMaxNormalizer不存在
/E:/1/datumbox-framework/datumbox-framework-applications/src/test/java/com/datumbox/framework/applications/datamodeling/ModelerTest.java:[70,88] 程序包DummyXMinMaxNormalizer不存在
-> [Help 1]

To see the full stack trace of the errors, re-run Maven with the -e switch.
Re-run Maven using the -X switch to enable full debug logging.

For more information about the errors and possible solutions, please read the following articles:
[Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException

After correcting the problems, you can resume the build with the command
  mvn <goals> -rf :datumbox-framework-applications

--------------------------------------------------------------------------------------------------------------------------------
old product
private <ML extends AbstractClassifier, FS extends AbstractFeatureSelector> void trainAndValidate(
            ML.AbstractTrainingParameters modelerTrainingParameters,
            FS.AbstractTrainingParameters featureSelectorTrainingParameters,
            double expectedF1score,
            int testId) {
        Configuration configuration = Configuration.getConfiguration();
        
        
        String storageName = this.getClass().getSimpleName() + testId;
        
        Map<Object, URI> dataset = new HashMap<>();
        try {
            dataset.put("negative", this.getClass().getClassLoader().getResource("datasets/sentimentAnalysis.neg.txt").toURI());
            dataset.put("positive", this.getClass().getClassLoader().getResource("datasets/sentimentAnalysis.pos.txt").toURI());
        }
        catch(UncheckedIOException | URISyntaxException ex) {
            logger.warn("Unable to download datasets, skipping test.");
            throw new RuntimeException(ex);
        }

        TextClassifier.TrainingParameters trainingParameters = new TextClassifier.TrainingParameters();
        
        //Classifier configuration
        trainingParameters.setModelerTrainingParameters(modelerTrainingParameters);
        
        //data transfomation configuration
        trainingParameters.setDataTransformerTrainingParameters(null);
        
        //feature selection configuration
        trainingParameters.setFeatureSelectorTrainingParameters(featureSelectorTrainingParameters);
        
        //text extraction configuration
        NgramsExtractor.Parameters exParams = new NgramsExtractor.Parameters();
        exParams.setMaxDistanceBetweenKwds(2);
        exParams.setExaminationWindowLength(6);
        trainingParameters.setTextExtractorParameters(exParams);

        TextClassifier instance = MLBuilder.create(trainingParameters, configuration);
        instance.fit(dataset);
        instance.save(storageName);


        ClassificationMetrics vm = instance.validate(dataset);
        assertEquals(expectedF1score, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH);

        instance.close();
        //instance = null;
        
        
        
        instance = MLBuilder.load(TextClassifier.class, storageName, configuration);
        Dataframe validationData;
        try {
            validationData = instance.predict(this.getClass().getClassLoader().getResource("datasets/sentimentAnalysis.unlabelled.txt").toURI());
        }
        catch(UncheckedIOException | URISyntaxException ex) {
            logger.warn("Unable to download datasets, skipping test.");
            throw new RuntimeException(ex);
        }
        
        List<Object> expResult = Arrays.asList("negative","positive");
        int i = 0;
        for(Record r : validationData.values()) {
            assertEquals(expResult.get(i), r.getYPredicted());
            ++i;
        }
        
        instance.delete();
        validationData.close();
    }
----------------------------------------------------------------
old test
@Test
    public void testTrainAndValidate() {
        logger.info("testTrainAndValidate");
        
        Configuration configuration = Configuration.getConfiguration();
        
        Dataframe[] data = Datasets.carsNumeric(configuration);
        Dataframe trainingData = data[0];
        
        Dataframe validationData = data[1];
        
        
        String storageName = this.getClass().getSimpleName();

        Modeler.TrainingParameters trainingParameters = new Modeler.TrainingParameters();
        
        
        //Model Configuration

        MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters();
        modelTrainingParameters.setMultiProbabilityWeighted(true);
        trainingParameters.setModelerTrainingParameters(modelTrainingParameters);

        //data transfomation configuration
        DummyXMinMaxNormalizer.TrainingParameters dtParams = new DummyXMinMaxNormalizer.TrainingParameters();
        trainingParameters.setDataTransformerTrainingParameters(dtParams);
        
        //feature selection configuration
        trainingParameters.setFeatureSelectorTrainingParameters(null);

        Modeler instance = MLBuilder.create(trainingParameters, configuration);
        instance.fit(trainingData);
        instance.save(storageName);

        instance.close();

        instance = MLBuilder.load(Modeler.class, storageName, configuration);

        instance.predict(trainingData);

        ClassificationMetrics vm = new ClassificationMetrics(trainingData);

        double expResult2 = 0.8;
        assertEquals(expResult2, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH);

        trainingData.close();
        instance.close();
        //instance = null;


        instance = MLBuilder.load(Modeler.class, storageName, configuration);
        
        instance.predict(validationData);
        
        
        
        Map<Integer, Object> expResult = new HashMap<>();
        Map<Integer, Object> result = new HashMap<>();
        for(Map.Entry<Integer, Record> e : validationData.entries()) {
            Integer rId = e.getKey();
            Record r = e.getValue();
            expResult.put(rId, r.getY());
            result.put(rId, r.getYPredicted());
        }
        assertEquals(expResult, result);
        
        instance.delete();

        validationData.close();
    }
----------------------------------------------------------------
new product
private <ML extends AbstractClassifier, FS extends AbstractFeatureSelector> void trainAndValidate(
            ML.AbstractTrainingParameters modelerTrainingParameters,
            FS.AbstractTrainingParameters featureSelectorTrainingParameters,
            double expectedF1score,
            int testId) {
        Configuration configuration = Configuration.getConfiguration();
        
        
        String storageName = this.getClass().getSimpleName() + testId;
        
        Map<Object, URI> dataset = new HashMap<>();
        try {
            dataset.put("negative", this.getClass().getClassLoader().getResource("datasets/sentimentAnalysis.neg.txt").toURI());
            dataset.put("positive", this.getClass().getClassLoader().getResource("datasets/sentimentAnalysis.pos.txt").toURI());
        }
        catch(UncheckedIOException | URISyntaxException ex) {
            logger.warn("Unable to download datasets, skipping test.");
            throw new RuntimeException(ex);
        }

        TextClassifier.TrainingParameters trainingParameters = new TextClassifier.TrainingParameters();

        //numerical scaling configuration
        trainingParameters.setNumericalScalerTrainingParameters(null);

        //categorical encoding configuration
        trainingParameters.setCategoricalEncoderTrainingParameters(null);
        
        //feature selection configuration
        trainingParameters.setFeatureSelectorTrainingParameters(featureSelectorTrainingParameters);

        //classifier configuration
        trainingParameters.setModelerTrainingParameters(modelerTrainingParameters);
        
        //text extraction configuration
        NgramsExtractor.Parameters exParams = new NgramsExtractor.Parameters();
        exParams.setMaxDistanceBetweenKwds(2);
        exParams.setExaminationWindowLength(6);
        trainingParameters.setTextExtractorParameters(exParams);

        TextClassifier instance = MLBuilder.create(trainingParameters, configuration);
        instance.fit(dataset);
        instance.save(storageName);


        ClassificationMetrics vm = instance.validate(dataset);
        assertEquals(expectedF1score, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH);

        instance.close();
        
        
        
        instance = MLBuilder.load(TextClassifier.class, storageName, configuration);
        Dataframe validationData;
        try {
            validationData = instance.predict(this.getClass().getClassLoader().getResource("datasets/sentimentAnalysis.unlabelled.txt").toURI());
        }
        catch(UncheckedIOException | URISyntaxException ex) {
            logger.warn("Unable to download datasets, skipping test.");
            throw new RuntimeException(ex);
        }
        
        List<Object> expResult = Arrays.asList("negative","positive");
        int i = 0;
        for(Record r : validationData.values()) {
            assertEquals(expResult.get(i), r.getYPredicted());
            ++i;
        }
        
        instance.delete();
        validationData.close();
    }
----------------------------------------------------------------
new test
@Test
    public void testTrainAndValidate() {
        logger.info("testTrainAndValidate");
        
        Configuration configuration = Configuration.getConfiguration();
        
        Dataframe[] data = Datasets.carsNumeric(configuration);
        Dataframe trainingData = data[0];
        
        Dataframe validationData = data[1];
        
        
        String storageName = this.getClass().getSimpleName();

        Modeler.TrainingParameters trainingParameters = new Modeler.TrainingParameters();
        

        //numerical scaling configuration
        MinMaxScaler.TrainingParameters nsParams = new MinMaxScaler.TrainingParameters();
        trainingParameters.setNumericalScalerTrainingParameters(nsParams);

        //categorical encoding configuration
        CornerConstraintsEncoder.TrainingParameters ceParams = new CornerConstraintsEncoder.TrainingParameters();
        trainingParameters.setCategoricalEncoderTrainingParameters(ceParams);
        
        //feature selection configuration
        trainingParameters.setFeatureSelectorTrainingParameters(null);

        //model Configuration
        MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters();
        modelTrainingParameters.setMultiProbabilityWeighted(true);
        trainingParameters.setModelerTrainingParameters(modelTrainingParameters);

        Modeler instance = MLBuilder.create(trainingParameters, configuration);
        instance.fit(trainingData);
        instance.save(storageName);

        instance.close();

        instance = MLBuilder.load(Modeler.class, storageName, configuration);

        instance.predict(trainingData);

        ClassificationMetrics vm = new ClassificationMetrics(trainingData);

        double expResult2 = 0.8;
        assertEquals(expResult2, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH);

        trainingData.close();
        instance.close();


        instance = MLBuilder.load(Modeler.class, storageName, configuration);
        
        instance.predict(validationData);
        
        
        
        Map<Integer, Object> expResult = new HashMap<>();
        Map<Integer, Object> result = new HashMap<>();
        for(Map.Entry<Integer, Record> e : validationData.entries()) {
            Integer rId = e.getKey();
            Record r = e.getValue();
            expResult.put(rId, r.getY());
            result.put(rId, r.getYPredicted());
        }
        assertEquals(expResult, result);
        
        instance.delete();

        validationData.close();
    }
----------------------------------------------------------------
diff product
diff --git a/old_product.java b/new_product.java
index a06a241..028f586 100644
--- a/old_product.java
+++ b/new_product.java
@@ -19,15 +19,18 @@ private <ML extends AbstractClassifier, FS extends AbstractFeatureSelector> void
         }
 
         TextClassifier.TrainingParameters trainingParameters = new TextClassifier.TrainingParameters();
-        
-        //Classifier configuration
-        trainingParameters.setModelerTrainingParameters(modelerTrainingParameters);
-        
-        //data transfomation configuration
-        trainingParameters.setDataTransformerTrainingParameters(null);
+
+        //numerical scaling configuration
+        trainingParameters.setNumericalScalerTrainingParameters(null);
+
+        //categorical encoding configuration
+        trainingParameters.setCategoricalEncoderTrainingParameters(null);
         
         //feature selection configuration
         trainingParameters.setFeatureSelectorTrainingParameters(featureSelectorTrainingParameters);
+
+        //classifier configuration
+        trainingParameters.setModelerTrainingParameters(modelerTrainingParameters);
         
         //text extraction configuration
         NgramsExtractor.Parameters exParams = new NgramsExtractor.Parameters();
@@ -44,7 +47,6 @@ private <ML extends AbstractClassifier, FS extends AbstractFeatureSelector> void
         assertEquals(expectedF1score, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH);
 
         instance.close();
-        //instance = null;
         
         
         

----------------------------------------------------------------
diff test
diff --git a/old_test.java b/new_test.java
index bc7f05a..4d61db9 100644
--- a/old_test.java
+++ b/new_test.java
@@ -14,20 +14,23 @@
 
         Modeler.TrainingParameters trainingParameters = new Modeler.TrainingParameters();
         
-        
-        //Model Configuration
 
-        MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters();
-        modelTrainingParameters.setMultiProbabilityWeighted(true);
-        trainingParameters.setModelerTrainingParameters(modelTrainingParameters);
+        //numerical scaling configuration
+        MinMaxScaler.TrainingParameters nsParams = new MinMaxScaler.TrainingParameters();
+        trainingParameters.setNumericalScalerTrainingParameters(nsParams);
 
-        //data transfomation configuration
-        DummyXMinMaxNormalizer.TrainingParameters dtParams = new DummyXMinMaxNormalizer.TrainingParameters();
-        trainingParameters.setDataTransformerTrainingParameters(dtParams);
+        //categorical encoding configuration
+        CornerConstraintsEncoder.TrainingParameters ceParams = new CornerConstraintsEncoder.TrainingParameters();
+        trainingParameters.setCategoricalEncoderTrainingParameters(ceParams);
         
         //feature selection configuration
         trainingParameters.setFeatureSelectorTrainingParameters(null);
 
+        //model Configuration
+        MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters();
+        modelTrainingParameters.setMultiProbabilityWeighted(true);
+        trainingParameters.setModelerTrainingParameters(modelTrainingParameters);
+
         Modeler instance = MLBuilder.create(trainingParameters, configuration);
         instance.fit(trainingData);
         instance.save(storageName);
@@ -45,7 +48,6 @@
 
         trainingData.close();
         instance.close();
-        //instance = null;
 
 
         instance = MLBuilder.load(Modeler.class, storageName, configuration);

--------------------------------------------------------------------------------------------------------------------------------
sample diff product
diff --git a/old_product.java b/new_product.java
index 551025e..fda79d8 100644
--- a/old_product.java
+++ b/new_product.java
@@ -42,13 +42,11 @@ private <ML extends AbstractClassifier, FS extends AbstractFeatureSelector> void
         trainingParameters.setTextExtractorParameters(exParams);
         
         instance.fit(dataset, trainingParameters);
-        
 
-        /*
-        //TODO: restore this test
-        ClassificationMetrics.Metrics vm = instance.validate(dataset);
+
+        ClassificationMetrics vm = instance.validate(dataset);
         assertEquals(expectedF1score, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH);
-        */
+
         instance.close();
         //instance = null;
         

----------------------------------------------------------------
sample diff test
diff --git a/old_test.java b/new_test.java
index 7644d50..934ea2b 100644
--- a/old_test.java
+++ b/new_test.java
@@ -33,14 +33,13 @@
         trainingParameters.setFeatureSelectorTrainingParameters(null);
         
         instance.fit(trainingData, trainingParameters);
-        
-        /*
-        //TODO: restore this test
-        ClassificationMetrics.Metrics vm = instance.validate(trainingData);
+
+        instance.predict(trainingData);
+
+        ClassificationMetrics vm = new ClassificationMetrics(trainingData);
 
         double expResult2 = 0.8;
-        Assert.assertEquals(expResult2, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH);
-        */
+        assertEquals(expResult2, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH);
 
         instance.close();
         //instance = null;

----------------------------------------------------------------
coverage
0.0
--------------------------------------------------------------------------------------------------------------------------------
当前次数：1
----------------------------------------------------------------
LLM输出
<new_test>
@Test
    public void testTrainAndValidate() {
        logger.info("testTrainAndValidate");
        
        Configuration configuration = Configuration.getConfiguration();
        
        Dataframe[] data = Datasets.carsNumeric(configuration);
        Dataframe trainingData = data[0];
        
        Dataframe validationData = data[1];
        
        
        String storageName = this.getClass().getSimpleName();

        TextClassifier.TrainingParameters trainingParameters = new TextClassifier.TrainingParameters();
        
        
        //Model Configuration
        MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters();
        modelTrainingParameters.setMultiProbabilityWeighted(true);
        trainingParameters.setModelerTrainingParameters(modelTrainingParameters);

        //numerical scaling configuration
        trainingParameters.setNumericalScalerTrainingParameters(null);

        //categorical encoding configuration
        trainingParameters.setCategoricalEncoderTrainingParameters(null);
        
        //feature selection configuration
        trainingParameters.setFeatureSelectorTrainingParameters(null);

        //text extraction configuration
        NgramsExtractor.Parameters exParams = new NgramsExtractor.Parameters();
        
        TextClassifier instance = MLBuilder.create(trainingParameters, configuration);
        instance.fit(trainingData);
        instance.save(storageName);

        instance.close();

        instance = MLBuilder.load(TextClassifier.class, storageName, configuration);

        instance.predict(trainingData);

        ClassificationMetrics vm = new ClassificationMetrics(trainingData);

        double expResult2 = 0.8;
        assertEquals(expResult2, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH);

        trainingData.close();
        instance.close();
        
        instance = MLBuilder.load(TextClassifier.class, storageName, configuration);
        
        instance.predict(validationData);
        
        Map<Integer, Object> expResult = new HashMap<>();
        Map<Integer, Object> result = new HashMap<>();
        for(Map.Entry<Integer, Record> e : validationData.entries()) {
            Integer rId = e.getKey();
            Record r = e.getValue();
            expResult.put(rId, r.getY());
            result.put(rId, r.getYPredicted());
        }
        assertEquals(expResult, result);
        
        instance.delete();

        validationData.close();
    }
</new_test>

----------------------------------------------------------------
测试代码

@Test
    public void testTrainAndValidate() {
        logger.info("testTrainAndValidate");
        
        Configuration configuration = Configuration.getConfiguration();
        
        Dataframe[] data = Datasets.carsNumeric(configuration);
        Dataframe trainingData = data[0];
        
        Dataframe validationData = data[1];
        
        
        String storageName = this.getClass().getSimpleName();

        TextClassifier.TrainingParameters trainingParameters = new TextClassifier.TrainingParameters();
        
        
        //Model Configuration
        MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters();
        modelTrainingParameters.setMultiProbabilityWeighted(true);
        trainingParameters.setModelerTrainingParameters(modelTrainingParameters);

        //numerical scaling configuration
        trainingParameters.setNumericalScalerTrainingParameters(null);

        //categorical encoding configuration
        trainingParameters.setCategoricalEncoderTrainingParameters(null);
        
        //feature selection configuration
        trainingParameters.setFeatureSelectorTrainingParameters(null);

        //text extraction configuration
        NgramsExtractor.Parameters exParams = new NgramsExtractor.Parameters();
        
        TextClassifier instance = MLBuilder.create(trainingParameters, configuration);
        instance.fit(trainingData);
        instance.save(storageName);

        instance.close();

        instance = MLBuilder.load(TextClassifier.class, storageName, configuration);

        instance.predict(trainingData);

        ClassificationMetrics vm = new ClassificationMetrics(trainingData);

        double expResult2 = 0.8;
        assertEquals(expResult2, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH);

        trainingData.close();
        instance.close();
        
        instance = MLBuilder.load(TextClassifier.class, storageName, configuration);
        
        instance.predict(validationData);
        
        Map<Integer, Object> expResult = new HashMap<>();
        Map<Integer, Object> result = new HashMap<>();
        for(Map.Entry<Integer, Record> e : validationData.entries()) {
            Integer rId = e.getKey();
            Record r = e.getValue();
            expResult.put(rId, r.getY());
            result.put(rId, r.getYPredicted());
        }
        assertEquals(expResult, result);
        
        instance.delete();

        validationData.close();
    }

----------------------------------------------------------------
改动
--- 

+++ 

@@ -1,3 +1,4 @@

+
 @Test
     public void testTrainAndValidate() {
         logger.info("testTrainAndValidate");
@@ -12,29 +13,33 @@

         
         String storageName = this.getClass().getSimpleName();
 
-        Modeler.TrainingParameters trainingParameters = new Modeler.TrainingParameters();
+        TextClassifier.TrainingParameters trainingParameters = new TextClassifier.TrainingParameters();
         
         
         //Model Configuration
-
         MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters();
         modelTrainingParameters.setMultiProbabilityWeighted(true);
         trainingParameters.setModelerTrainingParameters(modelTrainingParameters);
 
-        //data transfomation configuration
-        DummyXMinMaxNormalizer.TrainingParameters dtParams = new DummyXMinMaxNormalizer.TrainingParameters();
-        trainingParameters.setDataTransformerTrainingParameters(dtParams);
+        //numerical scaling configuration
+        trainingParameters.setNumericalScalerTrainingParameters(null);
+
+        //categorical encoding configuration
+        trainingParameters.setCategoricalEncoderTrainingParameters(null);
         
         //feature selection configuration
         trainingParameters.setFeatureSelectorTrainingParameters(null);
 
-        Modeler instance = MLBuilder.create(trainingParameters, configuration);
+        //text extraction configuration
+        NgramsExtractor.Parameters exParams = new NgramsExtractor.Parameters();
+        
+        TextClassifier instance = MLBuilder.create(trainingParameters, configuration);
         instance.fit(trainingData);
         instance.save(storageName);
 
         instance.close();
 
-        instance = MLBuilder.load(Modeler.class, storageName, configuration);
+        instance = MLBuilder.load(TextClassifier.class, storageName, configuration);
 
         instance.predict(trainingData);
 
@@ -45,14 +50,10 @@

 
         trainingData.close();
         instance.close();
-        //instance = null;
-
-
-        instance = MLBuilder.load(Modeler.class, storageName, configuration);
+        
+        instance = MLBuilder.load(TextClassifier.class, storageName, configuration);
         
         instance.predict(validationData);
-        
-        
         
         Map<Integer, Object> expResult = new HashMap<>();
         Map<Integer, Object> result = new HashMap<>();
@@ -68,3 +69,4 @@

 
         validationData.close();
     }
+

----------------------------------------------------------------
state
0
----------------------------------------------------------------
description
编译报错
----------------------------------------------------------------
message
COMPILATION ERROR : 
/E:/1/datumbox-framework/datumbox-framework-applications/src/test/java/com/datumbox/framework/applications/datamodeling/ModelerTest.java:[61,23] 程序包TextClassifier不存在
/E:/1/datumbox-framework/datumbox-framework-applications/src/test/java/com/datumbox/framework/applications/datamodeling/ModelerTest.java:[61,82] 程序包TextClassifier不存在
/E:/1/datumbox-framework/datumbox-framework-applications/src/test/java/com/datumbox/framework/applications/datamodeling/ModelerTest.java:[79,24] 程序包NgramsExtractor不存在
/E:/1/datumbox-framework/datumbox-framework-applications/src/test/java/com/datumbox/framework/applications/datamodeling/ModelerTest.java:[79,66] 程序包NgramsExtractor不存在
/E:/1/datumbox-framework/datumbox-framework-applications/src/test/java/com/datumbox/framework/applications/datamodeling/ModelerTest.java:[81,9] 找不到符号
  符号:   类 TextClassifier
  位置: 类 com.datumbox.framework.applications.datamodeling.ModelerTest
/E:/1/datumbox-framework/datumbox-framework-applications/src/test/java/com/datumbox/framework/applications/datamodeling/ModelerTest.java:[87,35] 找不到符号
  符号:   类 TextClassifier
  位置: 类 com.datumbox.framework.applications.datamodeling.ModelerTest
/E:/1/datumbox-framework/datumbox-framework-applications/src/test/java/com/datumbox/framework/applications/datamodeling/ModelerTest.java:[99,35] 找不到符号
  符号:   类 TextClassifier
  位置: 类 com.datumbox.framework.applications.datamodeling.ModelerTest
Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.6.0:testCompile (default-testCompile) on project datumbox-framework-applications: Compilation failure: Compilation failure:
/E:/1/datumbox-framework/datumbox-framework-applications/src/test/java/com/datumbox/framework/applications/datamodeling/ModelerTest.java:[61,23] 程序包TextClassifier不存在
/E:/1/datumbox-framework/datumbox-framework-applications/src/test/java/com/datumbox/framework/applications/datamodeling/ModelerTest.java:[61,82] 程序包TextClassifier不存在
/E:/1/datumbox-framework/datumbox-framework-applications/src/test/java/com/datumbox/framework/applications/datamodeling/ModelerTest.java:[79,24] 程序包NgramsExtractor不存在
/E:/1/datumbox-framework/datumbox-framework-applications/src/test/java/com/datumbox/framework/applications/datamodeling/ModelerTest.java:[79,66] 程序包NgramsExtractor不存在
/E:/1/datumbox-framework/datumbox-framework-applications/src/test/java/com/datumbox/framework/applications/datamodeling/ModelerTest.java:[81,9] 找不到符号
符号:   类 TextClassifier
位置: 类 com.datumbox.framework.applications.datamodeling.ModelerTest
/E:/1/datumbox-framework/datumbox-framework-applications/src/test/java/com/datumbox/framework/applications/datamodeling/ModelerTest.java:[87,35] 找不到符号
符号:   类 TextClassifier
位置: 类 com.datumbox.framework.applications.datamodeling.ModelerTest
/E:/1/datumbox-framework/datumbox-framework-applications/src/test/java/com/datumbox/framework/applications/datamodeling/ModelerTest.java:[99,35] 找不到符号
符号:   类 TextClassifier
位置: 类 com.datumbox.framework.applications.datamodeling.ModelerTest
-> [Help 1]

To see the full stack trace of the errors, re-run Maven with the -e switch.
Re-run Maven using the -X switch to enable full debug logging.

For more information about the errors and possible solutions, please read the following articles:
[Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException

After correcting the problems, you can resume the build with the command
  mvn <goals> -rf :datumbox-framework-applications

--------------------------------------------------------------------------------------------------------------------------------
当前次数：2
----------------------------------------------------------------
LLM输出
<new_test>
@Test
    public void testTrainAndValidate() {
        logger.info("testTrainAndValidate");
        
        Configuration configuration = Configuration.getConfiguration();
        
        Dataframe[] data = Datasets.carsNumeric(configuration);
        Dataframe trainingData = data[0];
        
        Dataframe validationData = data[1];
        
        
        String storageName = this.getClass().getSimpleName();

        Modeler.TrainingParameters trainingParameters = new Modeler.TrainingParameters();
        
        
        //Model Configuration
        MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters();
        modelTrainingParameters.setMultiProbabilityWeighted(true);
        trainingParameters.setModelerTrainingParameters(modelTrainingParameters);

        //numerical scaling configuration
        trainingParameters.setNumericalScalerTrainingParameters(null);

        //categorical encoding configuration
        trainingParameters.setCategoricalEncoderTrainingParameters(null);
        
        //feature selection configuration
        trainingParameters.setFeatureSelectorTrainingParameters(null);

        Modeler instance = MLBuilder.create(trainingParameters, configuration);
        instance.fit(trainingData);
        instance.save(storageName);

        instance.close();

        instance = MLBuilder.load(Modeler.class, storageName, configuration);

        instance.predict(trainingData);

        ClassificationMetrics vm = new ClassificationMetrics(trainingData);

        double expResult2 = 0.8;
        assertEquals(expResult2, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH);

        trainingData.close();
        instance.close();
        
        instance = MLBuilder.load(Modeler.class, storageName, configuration);
        
        instance.predict(validationData);
        
        Map<Integer, Object> expResult = new HashMap<>();
        Map<Integer, Object> result = new HashMap<>();
        for(Map.Entry<Integer, Record> e : validationData.entries()) {
            Integer rId = e.getKey();
            Record r = e.getValue();
            expResult.put(rId, r.getY());
            result.put(rId, r.getYPredicted());
        }
        assertEquals(expResult, result);
        
        instance.delete();

        validationData.close();
    }
</new_test>
----------------------------------------------------------------
测试代码

@Test
    public void testTrainAndValidate() {
        logger.info("testTrainAndValidate");
        
        Configuration configuration = Configuration.getConfiguration();
        
        Dataframe[] data = Datasets.carsNumeric(configuration);
        Dataframe trainingData = data[0];
        
        Dataframe validationData = data[1];
        
        
        String storageName = this.getClass().getSimpleName();

        Modeler.TrainingParameters trainingParameters = new Modeler.TrainingParameters();
        
        
        //Model Configuration
        MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters();
        modelTrainingParameters.setMultiProbabilityWeighted(true);
        trainingParameters.setModelerTrainingParameters(modelTrainingParameters);

        //numerical scaling configuration
        trainingParameters.setNumericalScalerTrainingParameters(null);

        //categorical encoding configuration
        trainingParameters.setCategoricalEncoderTrainingParameters(null);
        
        //feature selection configuration
        trainingParameters.setFeatureSelectorTrainingParameters(null);

        Modeler instance = MLBuilder.create(trainingParameters, configuration);
        instance.fit(trainingData);
        instance.save(storageName);

        instance.close();

        instance = MLBuilder.load(Modeler.class, storageName, configuration);

        instance.predict(trainingData);

        ClassificationMetrics vm = new ClassificationMetrics(trainingData);

        double expResult2 = 0.8;
        assertEquals(expResult2, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH);

        trainingData.close();
        instance.close();
        
        instance = MLBuilder.load(Modeler.class, storageName, configuration);
        
        instance.predict(validationData);
        
        Map<Integer, Object> expResult = new HashMap<>();
        Map<Integer, Object> result = new HashMap<>();
        for(Map.Entry<Integer, Record> e : validationData.entries()) {
            Integer rId = e.getKey();
            Record r = e.getValue();
            expResult.put(rId, r.getY());
            result.put(rId, r.getYPredicted());
        }
        assertEquals(expResult, result);
        
        instance.delete();

        validationData.close();
    }

----------------------------------------------------------------
改动
--- 

+++ 

@@ -13,7 +13,7 @@

         
         String storageName = this.getClass().getSimpleName();
 
-        TextClassifier.TrainingParameters trainingParameters = new TextClassifier.TrainingParameters();
+        Modeler.TrainingParameters trainingParameters = new Modeler.TrainingParameters();
         
         
         //Model Configuration
@@ -30,16 +30,13 @@

         //feature selection configuration
         trainingParameters.setFeatureSelectorTrainingParameters(null);
 
-        //text extraction configuration
-        NgramsExtractor.Parameters exParams = new NgramsExtractor.Parameters();
-        
-        TextClassifier instance = MLBuilder.create(trainingParameters, configuration);
+        Modeler instance = MLBuilder.create(trainingParameters, configuration);
         instance.fit(trainingData);
         instance.save(storageName);
 
         instance.close();
 
-        instance = MLBuilder.load(TextClassifier.class, storageName, configuration);
+        instance = MLBuilder.load(Modeler.class, storageName, configuration);
 
         instance.predict(trainingData);
 
@@ -51,7 +48,7 @@

         trainingData.close();
         instance.close();
         
-        instance = MLBuilder.load(TextClassifier.class, storageName, configuration);
+        instance = MLBuilder.load(Modeler.class, storageName, configuration);
         
         instance.predict(validationData);
         

----------------------------------------------------------------
state
3
----------------------------------------------------------------
description
测试通过，覆盖率：0.0
----------------------------------------------------------------
message

--------------------------------------------------------------------------------------------------------------------------------
总次数：2
----------------------------------------------------------------
generated test

@Test
    public void testTrainAndValidate() {
        logger.info("testTrainAndValidate");
        
        Configuration configuration = Configuration.getConfiguration();
        
        Dataframe[] data = Datasets.carsNumeric(configuration);
        Dataframe trainingData = data[0];
        
        Dataframe validationData = data[1];
        
        
        String storageName = this.getClass().getSimpleName();

        Modeler.TrainingParameters trainingParameters = new Modeler.TrainingParameters();
        
        
        //Model Configuration
        MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters();
        modelTrainingParameters.setMultiProbabilityWeighted(true);
        trainingParameters.setModelerTrainingParameters(modelTrainingParameters);

        //numerical scaling configuration
        trainingParameters.setNumericalScalerTrainingParameters(null);

        //categorical encoding configuration
        trainingParameters.setCategoricalEncoderTrainingParameters(null);
        
        //feature selection configuration
        trainingParameters.setFeatureSelectorTrainingParameters(null);

        Modeler instance = MLBuilder.create(trainingParameters, configuration);
        instance.fit(trainingData);
        instance.save(storageName);

        instance.close();

        instance = MLBuilder.load(Modeler.class, storageName, configuration);

        instance.predict(trainingData);

        ClassificationMetrics vm = new ClassificationMetrics(trainingData);

        double expResult2 = 0.8;
        assertEquals(expResult2, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH);

        trainingData.close();
        instance.close();
        
        instance = MLBuilder.load(Modeler.class, storageName, configuration);
        
        instance.predict(validationData);
        
        Map<Integer, Object> expResult = new HashMap<>();
        Map<Integer, Object> result = new HashMap<>();
        for(Map.Entry<Integer, Record> e : validationData.entries()) {
            Integer rId = e.getKey();
            Record r = e.getValue();
            expResult.put(rId, r.getY());
            result.put(rId, r.getYPredicted());
        }
        assertEquals(expResult, result);
        
        instance.delete();

        validationData.close();
    }

----------------------------------------------------------------
diff old generated test
--- 

+++ 

@@ -1,3 +1,4 @@

+
 @Test
     public void testTrainAndValidate() {
         logger.info("testTrainAndValidate");
@@ -16,14 +17,15 @@

         
         
         //Model Configuration
-
         MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters();
         modelTrainingParameters.setMultiProbabilityWeighted(true);
         trainingParameters.setModelerTrainingParameters(modelTrainingParameters);
 
-        //data transfomation configuration
-        DummyXMinMaxNormalizer.TrainingParameters dtParams = new DummyXMinMaxNormalizer.TrainingParameters();
-        trainingParameters.setDataTransformerTrainingParameters(dtParams);
+        //numerical scaling configuration
+        trainingParameters.setNumericalScalerTrainingParameters(null);
+
+        //categorical encoding configuration
+        trainingParameters.setCategoricalEncoderTrainingParameters(null);
         
         //feature selection configuration
         trainingParameters.setFeatureSelectorTrainingParameters(null);
@@ -45,14 +47,10 @@

 
         trainingData.close();
         instance.close();
-        //instance = null;
-
-
+        
         instance = MLBuilder.load(Modeler.class, storageName, configuration);
         
         instance.predict(validationData);
-        
-        
         
         Map<Integer, Object> expResult = new HashMap<>();
         Map<Integer, Object> result = new HashMap<>();
@@ -68,3 +66,4 @@

 
         validationData.close();
     }
+

----------------------------------------------------------------
diff generated new test
--- 

+++ 

@@ -1,4 +1,3 @@

-
 @Test
     public void testTrainAndValidate() {
         logger.info("testTrainAndValidate");
@@ -15,20 +14,22 @@

 
         Modeler.TrainingParameters trainingParameters = new Modeler.TrainingParameters();
         
+
+        //numerical scaling configuration
+        MinMaxScaler.TrainingParameters nsParams = new MinMaxScaler.TrainingParameters();
+        trainingParameters.setNumericalScalerTrainingParameters(nsParams);
+
+        //categorical encoding configuration
+        CornerConstraintsEncoder.TrainingParameters ceParams = new CornerConstraintsEncoder.TrainingParameters();
+        trainingParameters.setCategoricalEncoderTrainingParameters(ceParams);
         
-        //Model Configuration
+        //feature selection configuration
+        trainingParameters.setFeatureSelectorTrainingParameters(null);
+
+        //model Configuration
         MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters();
         modelTrainingParameters.setMultiProbabilityWeighted(true);
         trainingParameters.setModelerTrainingParameters(modelTrainingParameters);
-
-        //numerical scaling configuration
-        trainingParameters.setNumericalScalerTrainingParameters(null);
-
-        //categorical encoding configuration
-        trainingParameters.setCategoricalEncoderTrainingParameters(null);
-        
-        //feature selection configuration
-        trainingParameters.setFeatureSelectorTrainingParameters(null);
 
         Modeler instance = MLBuilder.create(trainingParameters, configuration);
         instance.fit(trainingData);
@@ -47,10 +48,13 @@

 
         trainingData.close();
         instance.close();
-        
+
+
         instance = MLBuilder.load(Modeler.class, storageName, configuration);
         
         instance.predict(validationData);
+        
+        
         
         Map<Integer, Object> expResult = new HashMap<>();
         Map<Integer, Object> result = new HashMap<>();
@@ -66,4 +70,3 @@

 
         validationData.close();
     }
-

--------------------------------------------------------------------------------------------------------------------------------
