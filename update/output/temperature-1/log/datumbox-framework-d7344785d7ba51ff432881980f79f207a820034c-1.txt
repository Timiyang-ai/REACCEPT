--------------------------------------------------------------------------------------------------------------------------------
new state
3
----------------------------------------------------------------
new description
测试通过，覆盖率：0.0
----------------------------------------------------------------
new message

--------------------------------------------------------------------------------------------------------------------------------
old state
0
----------------------------------------------------------------
old description
编译报错
----------------------------------------------------------------
old message
COMPILATION ERROR : 
/E:/1/datumbox-framework/datumbox-framework-applications/src/test/java/com/datumbox/framework/applications/datamodeling/ModelerTest.java:[70,31] 程序包DummyXMinMaxNormalizer不存在
/E:/1/datumbox-framework/datumbox-framework-applications/src/test/java/com/datumbox/framework/applications/datamodeling/ModelerTest.java:[70,88] 程序包DummyXMinMaxNormalizer不存在
Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.6.0:testCompile (default-testCompile) on project datumbox-framework-applications: Compilation failure: Compilation failure:
/E:/1/datumbox-framework/datumbox-framework-applications/src/test/java/com/datumbox/framework/applications/datamodeling/ModelerTest.java:[70,31] 程序包DummyXMinMaxNormalizer不存在
/E:/1/datumbox-framework/datumbox-framework-applications/src/test/java/com/datumbox/framework/applications/datamodeling/ModelerTest.java:[70,88] 程序包DummyXMinMaxNormalizer不存在
-> [Help 1]

To see the full stack trace of the errors, re-run Maven with the -e switch.
Re-run Maven using the -X switch to enable full debug logging.

For more information about the errors and possible solutions, please read the following articles:
[Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException

After correcting the problems, you can resume the build with the command
  mvn <goals> -rf :datumbox-framework-applications

--------------------------------------------------------------------------------------------------------------------------------
old product
private <ML extends AbstractClassifier, FS extends AbstractFeatureSelector> void trainAndValidate(
            ML.AbstractTrainingParameters modelerTrainingParameters,
            FS.AbstractTrainingParameters featureSelectorTrainingParameters,
            double expectedF1score,
            int testId) {
        Configuration configuration = Configuration.getConfiguration();
        
        
        String storageName = this.getClass().getSimpleName() + testId;
        
        Map<Object, URI> dataset = new HashMap<>();
        try {
            dataset.put("negative", this.getClass().getClassLoader().getResource("datasets/sentimentAnalysis.neg.txt").toURI());
            dataset.put("positive", this.getClass().getClassLoader().getResource("datasets/sentimentAnalysis.pos.txt").toURI());
        }
        catch(UncheckedIOException | URISyntaxException ex) {
            logger.warn("Unable to download datasets, skipping test.");
            throw new RuntimeException(ex);
        }

        TextClassifier.TrainingParameters trainingParameters = new TextClassifier.TrainingParameters();
        
        //Classifier configuration
        trainingParameters.setModelerTrainingParameters(modelerTrainingParameters);
        
        //data transfomation configuration
        trainingParameters.setDataTransformerTrainingParameters(null);
        
        //feature selection configuration
        trainingParameters.setFeatureSelectorTrainingParameters(featureSelectorTrainingParameters);
        
        //text extraction configuration
        NgramsExtractor.Parameters exParams = new NgramsExtractor.Parameters();
        exParams.setMaxDistanceBetweenKwds(2);
        exParams.setExaminationWindowLength(6);
        trainingParameters.setTextExtractorParameters(exParams);

        TextClassifier instance = MLBuilder.create(trainingParameters, configuration);
        instance.fit(dataset);
        instance.save(storageName);


        ClassificationMetrics vm = instance.validate(dataset);
        assertEquals(expectedF1score, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH);

        instance.close();
        //instance = null;
        
        
        
        instance = MLBuilder.load(TextClassifier.class, storageName, configuration);
        Dataframe validationData;
        try {
            validationData = instance.predict(this.getClass().getClassLoader().getResource("datasets/sentimentAnalysis.unlabelled.txt").toURI());
        }
        catch(UncheckedIOException | URISyntaxException ex) {
            logger.warn("Unable to download datasets, skipping test.");
            throw new RuntimeException(ex);
        }
        
        List<Object> expResult = Arrays.asList("negative","positive");
        int i = 0;
        for(Record r : validationData.values()) {
            assertEquals(expResult.get(i), r.getYPredicted());
            ++i;
        }
        
        instance.delete();
        validationData.close();
    }
----------------------------------------------------------------
old test
@Test
    public void testTrainAndValidate() {
        logger.info("testTrainAndValidate");
        
        Configuration configuration = Configuration.getConfiguration();
        
        Dataframe[] data = Datasets.carsNumeric(configuration);
        Dataframe trainingData = data[0];
        
        Dataframe validationData = data[1];
        
        
        String storageName = this.getClass().getSimpleName();

        Modeler.TrainingParameters trainingParameters = new Modeler.TrainingParameters();
        
        
        //Model Configuration

        MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters();
        modelTrainingParameters.setMultiProbabilityWeighted(true);
        trainingParameters.setModelerTrainingParameters(modelTrainingParameters);

        //data transfomation configuration
        DummyXMinMaxNormalizer.TrainingParameters dtParams = new DummyXMinMaxNormalizer.TrainingParameters();
        trainingParameters.setDataTransformerTrainingParameters(dtParams);
        
        //feature selection configuration
        trainingParameters.setFeatureSelectorTrainingParameters(null);

        Modeler instance = MLBuilder.create(trainingParameters, configuration);
        instance.fit(trainingData);
        instance.save(storageName);

        instance.close();

        instance = MLBuilder.load(Modeler.class, storageName, configuration);

        instance.predict(trainingData);

        ClassificationMetrics vm = new ClassificationMetrics(trainingData);

        double expResult2 = 0.8;
        assertEquals(expResult2, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH);

        trainingData.close();
        instance.close();
        //instance = null;


        instance = MLBuilder.load(Modeler.class, storageName, configuration);
        
        instance.predict(validationData);
        
        
        
        Map<Integer, Object> expResult = new HashMap<>();
        Map<Integer, Object> result = new HashMap<>();
        for(Map.Entry<Integer, Record> e : validationData.entries()) {
            Integer rId = e.getKey();
            Record r = e.getValue();
            expResult.put(rId, r.getY());
            result.put(rId, r.getYPredicted());
        }
        assertEquals(expResult, result);
        
        instance.delete();

        validationData.close();
    }
----------------------------------------------------------------
new product
private <ML extends AbstractClassifier, FS extends AbstractFeatureSelector> void trainAndValidate(
            ML.AbstractTrainingParameters modelerTrainingParameters,
            FS.AbstractTrainingParameters featureSelectorTrainingParameters,
            double expectedF1score,
            int testId) {
        Configuration configuration = Configuration.getConfiguration();
        
        
        String storageName = this.getClass().getSimpleName() + testId;
        
        Map<Object, URI> dataset = new HashMap<>();
        try {
            dataset.put("negative", this.getClass().getClassLoader().getResource("datasets/sentimentAnalysis.neg.txt").toURI());
            dataset.put("positive", this.getClass().getClassLoader().getResource("datasets/sentimentAnalysis.pos.txt").toURI());
        }
        catch(UncheckedIOException | URISyntaxException ex) {
            logger.warn("Unable to download datasets, skipping test.");
            throw new RuntimeException(ex);
        }

        TextClassifier.TrainingParameters trainingParameters = new TextClassifier.TrainingParameters();

        //numerical scaling configuration
        trainingParameters.setNumericalScalerTrainingParameters(null);

        //categorical encoding configuration
        trainingParameters.setCategoricalEncoderTrainingParameters(null);
        
        //feature selection configuration
        trainingParameters.setFeatureSelectorTrainingParameters(featureSelectorTrainingParameters);

        //classifier configuration
        trainingParameters.setModelerTrainingParameters(modelerTrainingParameters);
        
        //text extraction configuration
        NgramsExtractor.Parameters exParams = new NgramsExtractor.Parameters();
        exParams.setMaxDistanceBetweenKwds(2);
        exParams.setExaminationWindowLength(6);
        trainingParameters.setTextExtractorParameters(exParams);

        TextClassifier instance = MLBuilder.create(trainingParameters, configuration);
        instance.fit(dataset);
        instance.save(storageName);


        ClassificationMetrics vm = instance.validate(dataset);
        assertEquals(expectedF1score, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH);

        instance.close();
        
        
        
        instance = MLBuilder.load(TextClassifier.class, storageName, configuration);
        Dataframe validationData;
        try {
            validationData = instance.predict(this.getClass().getClassLoader().getResource("datasets/sentimentAnalysis.unlabelled.txt").toURI());
        }
        catch(UncheckedIOException | URISyntaxException ex) {
            logger.warn("Unable to download datasets, skipping test.");
            throw new RuntimeException(ex);
        }
        
        List<Object> expResult = Arrays.asList("negative","positive");
        int i = 0;
        for(Record r : validationData.values()) {
            assertEquals(expResult.get(i), r.getYPredicted());
            ++i;
        }
        
        instance.delete();
        validationData.close();
    }
----------------------------------------------------------------
new test
@Test
    public void testTrainAndValidate() {
        logger.info("testTrainAndValidate");
        
        Configuration configuration = Configuration.getConfiguration();
        
        Dataframe[] data = Datasets.carsNumeric(configuration);
        Dataframe trainingData = data[0];
        
        Dataframe validationData = data[1];
        
        
        String storageName = this.getClass().getSimpleName();

        Modeler.TrainingParameters trainingParameters = new Modeler.TrainingParameters();
        

        //numerical scaling configuration
        MinMaxScaler.TrainingParameters nsParams = new MinMaxScaler.TrainingParameters();
        trainingParameters.setNumericalScalerTrainingParameters(nsParams);

        //categorical encoding configuration
        CornerConstraintsEncoder.TrainingParameters ceParams = new CornerConstraintsEncoder.TrainingParameters();
        trainingParameters.setCategoricalEncoderTrainingParameters(ceParams);
        
        //feature selection configuration
        trainingParameters.setFeatureSelectorTrainingParameters(null);

        //model Configuration
        MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters();
        modelTrainingParameters.setMultiProbabilityWeighted(true);
        trainingParameters.setModelerTrainingParameters(modelTrainingParameters);

        Modeler instance = MLBuilder.create(trainingParameters, configuration);
        instance.fit(trainingData);
        instance.save(storageName);

        instance.close();

        instance = MLBuilder.load(Modeler.class, storageName, configuration);

        instance.predict(trainingData);

        ClassificationMetrics vm = new ClassificationMetrics(trainingData);

        double expResult2 = 0.8;
        assertEquals(expResult2, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH);

        trainingData.close();
        instance.close();


        instance = MLBuilder.load(Modeler.class, storageName, configuration);
        
        instance.predict(validationData);
        
        
        
        Map<Integer, Object> expResult = new HashMap<>();
        Map<Integer, Object> result = new HashMap<>();
        for(Map.Entry<Integer, Record> e : validationData.entries()) {
            Integer rId = e.getKey();
            Record r = e.getValue();
            expResult.put(rId, r.getY());
            result.put(rId, r.getYPredicted());
        }
        assertEquals(expResult, result);
        
        instance.delete();

        validationData.close();
    }
----------------------------------------------------------------
diff product
diff --git a/old_product.java b/new_product.java
index a06a241..028f586 100644
--- a/old_product.java
+++ b/new_product.java
@@ -19,15 +19,18 @@ private <ML extends AbstractClassifier, FS extends AbstractFeatureSelector> void
         }
 
         TextClassifier.TrainingParameters trainingParameters = new TextClassifier.TrainingParameters();
-        
-        //Classifier configuration
-        trainingParameters.setModelerTrainingParameters(modelerTrainingParameters);
-        
-        //data transfomation configuration
-        trainingParameters.setDataTransformerTrainingParameters(null);
+
+        //numerical scaling configuration
+        trainingParameters.setNumericalScalerTrainingParameters(null);
+
+        //categorical encoding configuration
+        trainingParameters.setCategoricalEncoderTrainingParameters(null);
         
         //feature selection configuration
         trainingParameters.setFeatureSelectorTrainingParameters(featureSelectorTrainingParameters);
+
+        //classifier configuration
+        trainingParameters.setModelerTrainingParameters(modelerTrainingParameters);
         
         //text extraction configuration
         NgramsExtractor.Parameters exParams = new NgramsExtractor.Parameters();
@@ -44,7 +47,6 @@ private <ML extends AbstractClassifier, FS extends AbstractFeatureSelector> void
         assertEquals(expectedF1score, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH);
 
         instance.close();
-        //instance = null;
         
         
         

----------------------------------------------------------------
diff test
diff --git a/old_test.java b/new_test.java
index bc7f05a..4d61db9 100644
--- a/old_test.java
+++ b/new_test.java
@@ -14,20 +14,23 @@
 
         Modeler.TrainingParameters trainingParameters = new Modeler.TrainingParameters();
         
-        
-        //Model Configuration
 
-        MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters();
-        modelTrainingParameters.setMultiProbabilityWeighted(true);
-        trainingParameters.setModelerTrainingParameters(modelTrainingParameters);
+        //numerical scaling configuration
+        MinMaxScaler.TrainingParameters nsParams = new MinMaxScaler.TrainingParameters();
+        trainingParameters.setNumericalScalerTrainingParameters(nsParams);
 
-        //data transfomation configuration
-        DummyXMinMaxNormalizer.TrainingParameters dtParams = new DummyXMinMaxNormalizer.TrainingParameters();
-        trainingParameters.setDataTransformerTrainingParameters(dtParams);
+        //categorical encoding configuration
+        CornerConstraintsEncoder.TrainingParameters ceParams = new CornerConstraintsEncoder.TrainingParameters();
+        trainingParameters.setCategoricalEncoderTrainingParameters(ceParams);
         
         //feature selection configuration
         trainingParameters.setFeatureSelectorTrainingParameters(null);
 
+        //model Configuration
+        MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters();
+        modelTrainingParameters.setMultiProbabilityWeighted(true);
+        trainingParameters.setModelerTrainingParameters(modelTrainingParameters);
+
         Modeler instance = MLBuilder.create(trainingParameters, configuration);
         instance.fit(trainingData);
         instance.save(storageName);
@@ -45,7 +48,6 @@
 
         trainingData.close();
         instance.close();
-        //instance = null;
 
 
         instance = MLBuilder.load(Modeler.class, storageName, configuration);

--------------------------------------------------------------------------------------------------------------------------------
sample diff product
diff --git a/old_product.java b/new_product.java
index 551025e..fda79d8 100644
--- a/old_product.java
+++ b/new_product.java
@@ -42,13 +42,11 @@ private <ML extends AbstractClassifier, FS extends AbstractFeatureSelector> void
         trainingParameters.setTextExtractorParameters(exParams);
         
         instance.fit(dataset, trainingParameters);
-        
 
-        /*
-        //TODO: restore this test
-        ClassificationMetrics.Metrics vm = instance.validate(dataset);
+
+        ClassificationMetrics vm = instance.validate(dataset);
         assertEquals(expectedF1score, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH);
-        */
+
         instance.close();
         //instance = null;
         

----------------------------------------------------------------
sample diff test
diff --git a/old_test.java b/new_test.java
index 7644d50..934ea2b 100644
--- a/old_test.java
+++ b/new_test.java
@@ -33,14 +33,13 @@
         trainingParameters.setFeatureSelectorTrainingParameters(null);
         
         instance.fit(trainingData, trainingParameters);
-        
-        /*
-        //TODO: restore this test
-        ClassificationMetrics.Metrics vm = instance.validate(trainingData);
+
+        instance.predict(trainingData);
+
+        ClassificationMetrics vm = new ClassificationMetrics(trainingData);
 
         double expResult2 = 0.8;
-        Assert.assertEquals(expResult2, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH);
-        */
+        assertEquals(expResult2, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH);
 
         instance.close();
         //instance = null;

----------------------------------------------------------------
coverage
0.0
--------------------------------------------------------------------------------------------------------------------------------
当前次数：1
----------------------------------------------------------------
LLM输出
<new_test>
@Test
    public void testTrainAndValidate() {
        logger.info("testTrainAndValidate");
        
        Configuration configuration = Configuration.getConfiguration();
        
        Dataframe[] data = Datasets.carsNumeric(configuration);
        Dataframe trainingData = data[0];
        
        Dataframe validationData = data[1];
        
        
        String storageName = this.getClass().getSimpleName();

        TextClassifier.TrainingParameters trainingParameters = new TextClassifier.TrainingParameters();
        
        
        //numerical scaling configuration
        trainingParameters.setNumericalScalerTrainingParameters(null);

        //categorical encoding configuration
        trainingParameters.setCategoricalEncoderTrainingParameters(null);

        //feature selection configuration
        trainingParameters.setFeatureSelectorTrainingParameters(null);
        
        //Classifier Configuration
        MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters();
        modelTrainingParameters.setMultiProbabilityWeighted(true);
        trainingParameters.setModelerTrainingParameters(modelTrainingParameters);
        
        //text extraction configuration
        NgramsExtractor.Parameters exParams = new NgramsExtractor.Parameters();
        trainingParameters.setTextExtractorParameters(exParams);

        Modeler instance = MLBuilder.create(trainingParameters, configuration);
        instance.fit(trainingData);
        instance.save(storageName);

        instance.close();

        instance = MLBuilder.load(Modeler.class, storageName, configuration);

        instance.predict(trainingData);

        ClassificationMetrics vm = new ClassificationMetrics(trainingData);

        double expResult2 = 0.8;
        assertEquals(expResult2, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH);

        trainingData.close();
        instance.close();


        instance = MLBuilder.load(Modeler.class, storageName, configuration);
        
        instance.predict(validationData);
        
        
        
        Map<Integer, Object> expResult = new HashMap<>();
        Map<Integer, Object> result = new HashMap<>();
        for(Map.Entry<Integer, Record> e : validationData.entries()) {
            Integer rId = e.getKey();
            Record r = e.getValue();
            expResult.put(rId, r.getY());
            result.put(rId, r.getYPredicted());
        }
        assertEquals(expResult, result);
        
        instance.delete();

        validationData.close();
    }
</new_test>
----------------------------------------------------------------
测试代码

@Test
    public void testTrainAndValidate() {
        logger.info("testTrainAndValidate");
        
        Configuration configuration = Configuration.getConfiguration();
        
        Dataframe[] data = Datasets.carsNumeric(configuration);
        Dataframe trainingData = data[0];
        
        Dataframe validationData = data[1];
        
        
        String storageName = this.getClass().getSimpleName();

        TextClassifier.TrainingParameters trainingParameters = new TextClassifier.TrainingParameters();
        
        
        //numerical scaling configuration
        trainingParameters.setNumericalScalerTrainingParameters(null);

        //categorical encoding configuration
        trainingParameters.setCategoricalEncoderTrainingParameters(null);

        //feature selection configuration
        trainingParameters.setFeatureSelectorTrainingParameters(null);
        
        //Classifier Configuration
        MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters();
        modelTrainingParameters.setMultiProbabilityWeighted(true);
        trainingParameters.setModelerTrainingParameters(modelTrainingParameters);
        
        //text extraction configuration
        NgramsExtractor.Parameters exParams = new NgramsExtractor.Parameters();
        trainingParameters.setTextExtractorParameters(exParams);

        Modeler instance = MLBuilder.create(trainingParameters, configuration);
        instance.fit(trainingData);
        instance.save(storageName);

        instance.close();

        instance = MLBuilder.load(Modeler.class, storageName, configuration);

        instance.predict(trainingData);

        ClassificationMetrics vm = new ClassificationMetrics(trainingData);

        double expResult2 = 0.8;
        assertEquals(expResult2, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH);

        trainingData.close();
        instance.close();


        instance = MLBuilder.load(Modeler.class, storageName, configuration);
        
        instance.predict(validationData);
        
        
        
        Map<Integer, Object> expResult = new HashMap<>();
        Map<Integer, Object> result = new HashMap<>();
        for(Map.Entry<Integer, Record> e : validationData.entries()) {
            Integer rId = e.getKey();
            Record r = e.getValue();
            expResult.put(rId, r.getY());
            result.put(rId, r.getYPredicted());
        }
        assertEquals(expResult, result);
        
        instance.delete();

        validationData.close();
    }

----------------------------------------------------------------
改动
--- 

+++ 

@@ -1,3 +1,4 @@

+
 @Test
     public void testTrainAndValidate() {
         logger.info("testTrainAndValidate");
@@ -12,21 +13,26 @@

         
         String storageName = this.getClass().getSimpleName();
 
-        Modeler.TrainingParameters trainingParameters = new Modeler.TrainingParameters();
+        TextClassifier.TrainingParameters trainingParameters = new TextClassifier.TrainingParameters();
         
         
-        //Model Configuration
+        //numerical scaling configuration
+        trainingParameters.setNumericalScalerTrainingParameters(null);
 
+        //categorical encoding configuration
+        trainingParameters.setCategoricalEncoderTrainingParameters(null);
+
+        //feature selection configuration
+        trainingParameters.setFeatureSelectorTrainingParameters(null);
+        
+        //Classifier Configuration
         MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters();
         modelTrainingParameters.setMultiProbabilityWeighted(true);
         trainingParameters.setModelerTrainingParameters(modelTrainingParameters);
-
-        //data transfomation configuration
-        DummyXMinMaxNormalizer.TrainingParameters dtParams = new DummyXMinMaxNormalizer.TrainingParameters();
-        trainingParameters.setDataTransformerTrainingParameters(dtParams);
         
-        //feature selection configuration
-        trainingParameters.setFeatureSelectorTrainingParameters(null);
+        //text extraction configuration
+        NgramsExtractor.Parameters exParams = new NgramsExtractor.Parameters();
+        trainingParameters.setTextExtractorParameters(exParams);
 
         Modeler instance = MLBuilder.create(trainingParameters, configuration);
         instance.fit(trainingData);
@@ -45,7 +51,6 @@

 
         trainingData.close();
         instance.close();
-        //instance = null;
 
 
         instance = MLBuilder.load(Modeler.class, storageName, configuration);
@@ -68,3 +73,4 @@

 
         validationData.close();
     }
+

----------------------------------------------------------------
state
0
----------------------------------------------------------------
description
编译报错
----------------------------------------------------------------
message
COMPILATION ERROR : 
/E:/1/datumbox-framework/datumbox-framework-applications/src/test/java/com/datumbox/framework/applications/datamodeling/ModelerTest.java:[61,23] 程序包TextClassifier不存在
/E:/1/datumbox-framework/datumbox-framework-applications/src/test/java/com/datumbox/framework/applications/datamodeling/ModelerTest.java:[61,82] 程序包TextClassifier不存在
/E:/1/datumbox-framework/datumbox-framework-applications/src/test/java/com/datumbox/framework/applications/datamodeling/ModelerTest.java:[79,24] 程序包NgramsExtractor不存在
/E:/1/datumbox-framework/datumbox-framework-applications/src/test/java/com/datumbox/framework/applications/datamodeling/ModelerTest.java:[79,66] 程序包NgramsExtractor不存在
Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.6.0:testCompile (default-testCompile) on project datumbox-framework-applications: Compilation failure: Compilation failure:
/E:/1/datumbox-framework/datumbox-framework-applications/src/test/java/com/datumbox/framework/applications/datamodeling/ModelerTest.java:[61,23] 程序包TextClassifier不存在
/E:/1/datumbox-framework/datumbox-framework-applications/src/test/java/com/datumbox/framework/applications/datamodeling/ModelerTest.java:[61,82] 程序包TextClassifier不存在
/E:/1/datumbox-framework/datumbox-framework-applications/src/test/java/com/datumbox/framework/applications/datamodeling/ModelerTest.java:[79,24] 程序包NgramsExtractor不存在
/E:/1/datumbox-framework/datumbox-framework-applications/src/test/java/com/datumbox/framework/applications/datamodeling/ModelerTest.java:[79,66] 程序包NgramsExtractor不存在
-> [Help 1]

To see the full stack trace of the errors, re-run Maven with the -e switch.
Re-run Maven using the -X switch to enable full debug logging.

For more information about the errors and possible solutions, please read the following articles:
[Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException

After correcting the problems, you can resume the build with the command
  mvn <goals> -rf :datumbox-framework-applications

--------------------------------------------------------------------------------------------------------------------------------
当前次数：2
----------------------------------------------------------------
LLM输出
<new_test>
@Test
public void testTrainAndValidate() {
    logger.info("testTrainAndValidate");
    
    Configuration configuration = Configuration.getConfiguration();
    
    Dataframe[] data = Datasets.carsNumeric(configuration);
    Dataframe trainingData = data[0];
    
    Dataframe validationData = data[1];
    
    
    String storageName = this.getClass().getSimpleName();

    Modeler.TrainingParameters trainingParameters = new Modeler.TrainingParameters();
    
    
    //numerical scaling configuration
    trainingParameters.setNumericalScalerTrainingParameters(null);

    //categorical encoding configuration
    trainingParameters.setCategoricalEncoderTrainingParameters(null);

    //feature selection configuration
    trainingParameters.setFeatureSelectorTrainingParameters(null);
    
    //Model Configuration
    MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters();
    modelTrainingParameters.setMultiProbabilityWeighted(true);
    trainingParameters.setModelerTrainingParameters(modelTrainingParameters);
    

    Modeler instance = MLBuilder.create(trainingParameters, configuration);
    instance.fit(trainingData);
    instance.save(storageName);

    instance.close();

    instance = MLBuilder.load(Modeler.class, storage



Name, configuration);
    
    instance.predict(trainingData);
    
    ClassificationMetrics vm = new ClassificationMetrics(trainingData);
    
    double expResult2 = 0.8;
    assertEquals(expResult2, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH);
    
    trainingData.close();
    instance.close();


    instance = MLBuilder.load(Modeler.class, storageName, configuration);
    
    instance.predict(validationData);
    
    
    
    Map<Integer, Object> expResult = new HashMap<>();
    Map<Integer, Object> result = new HashMap<>();
    for(Map.Entry<Integer, Record> e : validationData.entries()) {
        Integer rId = e.getKey();
        Record r = e.getValue();
        expResult.put(rId, r.getY());
        result.put(rId, r.getYPredicted());
    }
    assertEquals(expResult, result);
    
    instance.delete();

    validationId.close();
}
</new_test>
----------------------------------------------------------------
测试代码

@Test
public void testTrainAndValidate() {
    logger.info("testTrainAndValidate");
    
    Configuration configuration = Configuration.getConfiguration();
    
    Dataframe[] data = Datasets.carsNumeric(configuration);
    Dataframe trainingData = data[0];
    
    Dataframe validationData = data[1];
    
    
    String storageName = this.getClass().getSimpleName();

    Modeler.TrainingParameters trainingParameters = new Modeler.TrainingParameters();
    
    
    //numerical scaling configuration
    trainingParameters.setNumericalScalerTrainingParameters(null);

    //categorical encoding configuration
    trainingParameters.setCategoricalEncoderTrainingParameters(null);

    //feature selection configuration
    trainingParameters.setFeatureSelectorTrainingParameters(null);
    
    //Model Configuration
    MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters();
    modelTrainingParameters.setMultiProbabilityWeighted(true);
    trainingParameters.setModelerTrainingParameters(modelTrainingParameters);
    

    Modeler instance = MLBuilder.create(trainingParameters, configuration);
    instance.fit(trainingData);
    instance.save(storageName);

    instance.close();

    instance = MLBuilder.load(Modeler.class, storage



Name, configuration);
    
    instance.predict(trainingData);
    
    ClassificationMetrics vm = new ClassificationMetrics(trainingData);
    
    double expResult2 = 0.8;
    assertEquals(expResult2, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH);
    
    trainingData.close();
    instance.close();


    instance = MLBuilder.load(Modeler.class, storageName, configuration);
    
    instance.predict(validationData);
    
    
    
    Map<Integer, Object> expResult = new HashMap<>();
    Map<Integer, Object> result = new HashMap<>();
    for(Map.Entry<Integer, Record> e : validationData.entries()) {
        Integer rId = e.getKey();
        Record r = e.getValue();
        expResult.put(rId, r.getY());
        result.put(rId, r.getYPredicted());
    }
    assertEquals(expResult, result);
    
    instance.delete();

    validationId.close();
}

----------------------------------------------------------------
改动
--- 

+++ 

@@ -1,76 +1,77 @@

 
 @Test
-    public void testTrainAndValidate() {
-        logger.info("testTrainAndValidate");
-        
-        Configuration configuration = Configuration.getConfiguration();
-        
-        Dataframe[] data = Datasets.carsNumeric(configuration);
-        Dataframe trainingData = data[0];
-        
-        Dataframe validationData = data[1];
-        
-        
-        String storageName = this.getClass().getSimpleName();
+public void testTrainAndValidate() {
+    logger.info("testTrainAndValidate");
+    
+    Configuration configuration = Configuration.getConfiguration();
+    
+    Dataframe[] data = Datasets.carsNumeric(configuration);
+    Dataframe trainingData = data[0];
+    
+    Dataframe validationData = data[1];
+    
+    
+    String storageName = this.getClass().getSimpleName();
 
-        TextClassifier.TrainingParameters trainingParameters = new TextClassifier.TrainingParameters();
-        
-        
-        //numerical scaling configuration
-        trainingParameters.setNumericalScalerTrainingParameters(null);
+    Modeler.TrainingParameters trainingParameters = new Modeler.TrainingParameters();
+    
+    
+    //numerical scaling configuration
+    trainingParameters.setNumericalScalerTrainingParameters(null);
 
-        //categorical encoding configuration
-        trainingParameters.setCategoricalEncoderTrainingParameters(null);
+    //categorical encoding configuration
+    trainingParameters.setCategoricalEncoderTrainingParameters(null);
 
-        //feature selection configuration
-        trainingParameters.setFeatureSelectorTrainingParameters(null);
-        
-        //Classifier Configuration
-        MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters();
-        modelTrainingParameters.setMultiProbabilityWeighted(true);
-        trainingParameters.setModelerTrainingParameters(modelTrainingParameters);
-        
-        //text extraction configuration
-        NgramsExtractor.Parameters exParams = new NgramsExtractor.Parameters();
-        trainingParameters.setTextExtractorParameters(exParams);
+    //feature selection configuration
+    trainingParameters.setFeatureSelectorTrainingParameters(null);
+    
+    //Model Configuration
+    MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters();
+    modelTrainingParameters.setMultiProbabilityWeighted(true);
+    trainingParameters.setModelerTrainingParameters(modelTrainingParameters);
+    
 
-        Modeler instance = MLBuilder.create(trainingParameters, configuration);
-        instance.fit(trainingData);
-        instance.save(storageName);
+    Modeler instance = MLBuilder.create(trainingParameters, configuration);
+    instance.fit(trainingData);
+    instance.save(storageName);
 
-        instance.close();
+    instance.close();
 
-        instance = MLBuilder.load(Modeler.class, storageName, configuration);
-
-        instance.predict(trainingData);
-
-        ClassificationMetrics vm = new ClassificationMetrics(trainingData);
-
-        double expResult2 = 0.8;
-        assertEquals(expResult2, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH);
-
-        trainingData.close();
-        instance.close();
+    instance = MLBuilder.load(Modeler.class, storage
 
 
-        instance = MLBuilder.load(Modeler.class, storageName, configuration);
-        
-        instance.predict(validationData);
-        
-        
-        
-        Map<Integer, Object> expResult = new HashMap<>();
-        Map<Integer, Object> result = new HashMap<>();
-        for(Map.Entry<Integer, Record> e : validationData.entries()) {
-            Integer rId = e.getKey();
-            Record r = e.getValue();
-            expResult.put(rId, r.getY());
-            result.put(rId, r.getYPredicted());
-        }
-        assertEquals(expResult, result);
-        
-        instance.delete();
 
-        validationData.close();
+Name, configuration);
+    
+    instance.predict(trainingData);
+    
+    ClassificationMetrics vm = new ClassificationMetrics(trainingData);
+    
+    double expResult2 = 0.8;
+    assertEquals(expResult2, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH);
+    
+    trainingData.close();
+    instance.close();
+
+
+    instance = MLBuilder.load(Modeler.class, storageName, configuration);
+    
+    instance.predict(validationData);
+    
+    
+    
+    Map<Integer, Object> expResult = new HashMap<>();
+    Map<Integer, Object> result = new HashMap<>();
+    for(Map.Entry<Integer, Record> e : validationData.entries()) {
+        Integer rId = e.getKey();
+        Record r = e.getValue();
+        expResult.put(rId, r.getY());
+        result.put(rId, r.getYPredicted());
     }
+    assertEquals(expResult, result);
+    
+    instance.delete();
 
+    validationId.close();
+}
+

----------------------------------------------------------------
state
0
----------------------------------------------------------------
description
编译报错
----------------------------------------------------------------
message
COMPILATION ERROR : 
/E:/1/datumbox-framework/datumbox-framework-applications/src/test/java/com/datumbox/framework/applications/datamodeling/ModelerTest.java:[85,53] 需要')'
/E:/1/datumbox-framework/datumbox-framework-applications/src/test/java/com/datumbox/framework/applications/datamodeling/ModelerTest.java:[89,5] 非法的表达式开始
/E:/1/datumbox-framework/datumbox-framework-applications/src/test/java/com/datumbox/framework/applications/datamodeling/ModelerTest.java:[89,20] 需要';'
Failed to execute goal org.apache.maven.plugins:maven-compiler-plugin:3.6.0:testCompile (default-testCompile) on project datumbox-framework-applications: Compilation failure: Compilation failure:
/E:/1/datumbox-framework/datumbox-framework-applications/src/test/java/com/datumbox/framework/applications/datamodeling/ModelerTest.java:[85,53] 需要')'
/E:/1/datumbox-framework/datumbox-framework-applications/src/test/java/com/datumbox/framework/applications/datamodeling/ModelerTest.java:[89,5] 非法的表达式开始
/E:/1/datumbox-framework/datumbox-framework-applications/src/test/java/com/datumbox/framework/applications/datamodeling/ModelerTest.java:[89,20] 需要';'
-> [Help 1]

To see the full stack trace of the errors, re-run Maven with the -e switch.
Re-run Maven using the -X switch to enable full debug logging.

For more information about the errors and possible solutions, please read the following articles:
[Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException

After correcting the problems, you can resume the build with the command
  mvn <goals> -rf :datumbox-framework-applications

--------------------------------------------------------------------------------------------------------------------------------
当前次数：3
----------------------------------------------------------------
LLM输出
I apologize for the oversight in my previous response. Here is a corrected version of the test method that should address the compilation errors.

<new_test>
```java
@Test
public void testTrainAndValidate() {
    logger.info("testTrainAndValidate");
    
    Configuration configuration = Configuration.getConfiguration();
    
    Dataframe[] data = Datasets.carsNumeric(configuration);
    Dataframe trainingData = data[0];
    Dataframe validationData = data[1];
    
    String storageName = this.getClass().getSimpleName();

    Modeler.TrainingParameters trainingParameters = new Modeler.TrainingParameters();
    
    // Model Configuration
    MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters();
    modelTrainingParameters.setMultiProbabilityWeighted(true);
    trainingParameters.setModelerTrainingParameters(modelTrainingParameters);

    // Numerical scaling and categorical encoding configuration
    trainingParameters.setNumericalScalerTrainingParameters(null);
    trainingParameters.setCategoricalEncoderTrainingParameters(null);

    // Feature selection configuration
    trainingParameters.setFeatureSelectorTrainingParameters(null);

    Modeler instance = MLBuilder.create(trainingParameters, configuration);
    instance.fit(trainingData);
    instance.save(storageName);

    instance.close();

    instance = MLBuilder.load(Modeler.class, storageName, configuration);
    
    instance.predict(trainingData);
    
    ClassificationMetrics vm = new ClassificationMetrics(trainingData);
    
    double expResult2 = 0.8;
    assertEquals(expResult2, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH);
    
    trainingData.close();
    instance.close();
    
    // Reload the instance for validation data prediction
    instance = MLBuilder.load(Modeler.class, storageName, configuration);
    instance.predict(validationData);
    
    Map<Integer, Object> expResult = new HashMap<>();
    Map<Integer, Object> result = new HashMap<>();
    for(Map.Entry<Integer, Record> e : validationData.entries()) {
        Integer rId = e.getKey();
        Record r = e.getValue();
        expResult.put(rId, r.getY());
        result.put(rId, r.getYPredicted());
    }
    
    assertEquals(expResult, result);
    
    instance.delete();
    validationData.close();
}
```
</new_test>

This version corrects the syntax errors, specifically addressing the incorrect method call and ensuring that all required closing parentheses and semicolons are present.
----------------------------------------------------------------
测试代码
@Test
public void testTrainAndValidate() {
    logger.info("testTrainAndValidate");
    
    Configuration configuration = Configuration.getConfiguration();
    
    Dataframe[] data = Datasets.carsNumeric(configuration);
    Dataframe trainingData = data[0];
    Dataframe validationData = data[1];
    
    String storageName = this.getClass().getSimpleName();

    Modeler.TrainingParameters trainingParameters = new Modeler.TrainingParameters();
    
    // Model Configuration
    MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters();
    modelTrainingParameters.setMultiProbabilityWeighted(true);
    trainingParameters.setModelerTrainingParameters(modelTrainingParameters);

    // Numerical scaling and categorical encoding configuration
    trainingParameters.setNumericalScalerTrainingParameters(null);
    trainingParameters.setCategoricalEncoderTrainingParameters(null);

    // Feature selection configuration
    trainingParameters.setFeatureSelectorTrainingParameters(null);

    Modeler instance = MLBuilder.create(trainingParameters, configuration);
    instance.fit(trainingData);
    instance.save(storageName);

    instance.close();

    instance = MLBuilder.load(Modeler.class, storageName, configuration);
    
    instance.predict(trainingData);
    
    ClassificationMetrics vm = new ClassificationMetrics(trainingData);
    
    double expResult2 = 0.8;
    assertEquals(expResult2, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH);
    
    trainingData.close();
    instance.close();
    
    // Reload the instance for validation data prediction
    instance = MLBuilder.load(Modeler.class, storageName, configuration);
    instance.predict(validationData);
    
    Map<Integer, Object> expResult = new HashMap<>();
    Map<Integer, Object> result = new HashMap<>();
    for(Map.Entry<Integer, Record> e : validationData.entries()) {
        Integer rId = e.getKey();
        Record r = e.getValue();
        expResult.put(rId, r.getY());
        result.put(rId, r.getYPredicted());
    }
    
    assertEquals(expResult, result);
    
    instance.delete();
    validationData.close();
}
----------------------------------------------------------------
改动
--- 

+++ 

@@ -1,4 +1,3 @@

-
 @Test
 public void testTrainAndValidate() {
     logger.info("testTrainAndValidate");
@@ -7,29 +6,23 @@

     
     Dataframe[] data = Datasets.carsNumeric(configuration);
     Dataframe trainingData = data[0];
-    
     Dataframe validationData = data[1];
-    
     
     String storageName = this.getClass().getSimpleName();
 
     Modeler.TrainingParameters trainingParameters = new Modeler.TrainingParameters();
     
-    
-    //numerical scaling configuration
-    trainingParameters.setNumericalScalerTrainingParameters(null);
-
-    //categorical encoding configuration
-    trainingParameters.setCategoricalEncoderTrainingParameters(null);
-
-    //feature selection configuration
-    trainingParameters.setFeatureSelectorTrainingParameters(null);
-    
-    //Model Configuration
+    // Model Configuration
     MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters();
     modelTrainingParameters.setMultiProbabilityWeighted(true);
     trainingParameters.setModelerTrainingParameters(modelTrainingParameters);
-    
+
+    // Numerical scaling and categorical encoding configuration
+    trainingParameters.setNumericalScalerTrainingParameters(null);
+    trainingParameters.setCategoricalEncoderTrainingParameters(null);
+
+    // Feature selection configuration
+    trainingParameters.setFeatureSelectorTrainingParameters(null);
 
     Modeler instance = MLBuilder.create(trainingParameters, configuration);
     instance.fit(trainingData);
@@ -37,11 +30,7 @@

 
     instance.close();
 
-    instance = MLBuilder.load(Modeler.class, storage
-
-
-
-Name, configuration);
+    instance = MLBuilder.load(Modeler.class, storageName, configuration);
     
     instance.predict(trainingData);
     
@@ -52,13 +41,10 @@

     
     trainingData.close();
     instance.close();
-
-
+    
+    // Reload the instance for validation data prediction
     instance = MLBuilder.load(Modeler.class, storageName, configuration);
-    
     instance.predict(validationData);
-    
-    
     
     Map<Integer, Object> expResult = new HashMap<>();
     Map<Integer, Object> result = new HashMap<>();
@@ -68,10 +54,9 @@

         expResult.put(rId, r.getY());
         result.put(rId, r.getYPredicted());
     }
+    
     assertEquals(expResult, result);
     
     instance.delete();
-
-    validationId.close();
+    validationData.close();
 }
-

----------------------------------------------------------------
state
3
----------------------------------------------------------------
description
测试通过，覆盖率：0.0
----------------------------------------------------------------
message

--------------------------------------------------------------------------------------------------------------------------------
总次数：3
----------------------------------------------------------------
generated test
@Test
public void testTrainAndValidate() {
    logger.info("testTrainAndValidate");
    
    Configuration configuration = Configuration.getConfiguration();
    
    Dataframe[] data = Datasets.carsNumeric(configuration);
    Dataframe trainingData = data[0];
    Dataframe validationData = data[1];
    
    String storageName = this.getClass().getSimpleName();

    Modeler.TrainingParameters trainingParameters = new Modeler.TrainingParameters();
    
    // Model Configuration
    MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters();
    modelTrainingParameters.setMultiProbabilityWeighted(true);
    trainingParameters.setModelerTrainingParameters(modelTrainingParameters);

    // Numerical scaling and categorical encoding configuration
    trainingParameters.setNumericalScalerTrainingParameters(null);
    trainingParameters.setCategoricalEncoderTrainingParameters(null);

    // Feature selection configuration
    trainingParameters.setFeatureSelectorTrainingParameters(null);

    Modeler instance = MLBuilder.create(trainingParameters, configuration);
    instance.fit(trainingData);
    instance.save(storageName);

    instance.close();

    instance = MLBuilder.load(Modeler.class, storageName, configuration);
    
    instance.predict(trainingData);
    
    ClassificationMetrics vm = new ClassificationMetrics(trainingData);
    
    double expResult2 = 0.8;
    assertEquals(expResult2, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH);
    
    trainingData.close();
    instance.close();
    
    // Reload the instance for validation data prediction
    instance = MLBuilder.load(Modeler.class, storageName, configuration);
    instance.predict(validationData);
    
    Map<Integer, Object> expResult = new HashMap<>();
    Map<Integer, Object> result = new HashMap<>();
    for(Map.Entry<Integer, Record> e : validationData.entries()) {
        Integer rId = e.getKey();
        Record r = e.getValue();
        expResult.put(rId, r.getY());
        result.put(rId, r.getYPredicted());
    }
    
    assertEquals(expResult, result);
    
    instance.delete();
    validationData.close();
}
----------------------------------------------------------------
diff old generated test
--- 

+++ 

@@ -1,70 +1,62 @@

 @Test
-    public void testTrainAndValidate() {
-        logger.info("testTrainAndValidate");
-        
-        Configuration configuration = Configuration.getConfiguration();
-        
-        Dataframe[] data = Datasets.carsNumeric(configuration);
-        Dataframe trainingData = data[0];
-        
-        Dataframe validationData = data[1];
-        
-        
-        String storageName = this.getClass().getSimpleName();
+public void testTrainAndValidate() {
+    logger.info("testTrainAndValidate");
+    
+    Configuration configuration = Configuration.getConfiguration();
+    
+    Dataframe[] data = Datasets.carsNumeric(configuration);
+    Dataframe trainingData = data[0];
+    Dataframe validationData = data[1];
+    
+    String storageName = this.getClass().getSimpleName();
 
-        Modeler.TrainingParameters trainingParameters = new Modeler.TrainingParameters();
-        
-        
-        //Model Configuration
+    Modeler.TrainingParameters trainingParameters = new Modeler.TrainingParameters();
+    
+    // Model Configuration
+    MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters();
+    modelTrainingParameters.setMultiProbabilityWeighted(true);
+    trainingParameters.setModelerTrainingParameters(modelTrainingParameters);
 
-        MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters();
-        modelTrainingParameters.setMultiProbabilityWeighted(true);
-        trainingParameters.setModelerTrainingParameters(modelTrainingParameters);
+    // Numerical scaling and categorical encoding configuration
+    trainingParameters.setNumericalScalerTrainingParameters(null);
+    trainingParameters.setCategoricalEncoderTrainingParameters(null);
 
-        //data transfomation configuration
-        DummyXMinMaxNormalizer.TrainingParameters dtParams = new DummyXMinMaxNormalizer.TrainingParameters();
-        trainingParameters.setDataTransformerTrainingParameters(dtParams);
-        
-        //feature selection configuration
-        trainingParameters.setFeatureSelectorTrainingParameters(null);
+    // Feature selection configuration
+    trainingParameters.setFeatureSelectorTrainingParameters(null);
 
-        Modeler instance = MLBuilder.create(trainingParameters, configuration);
-        instance.fit(trainingData);
-        instance.save(storageName);
+    Modeler instance = MLBuilder.create(trainingParameters, configuration);
+    instance.fit(trainingData);
+    instance.save(storageName);
 
-        instance.close();
+    instance.close();
 
-        instance = MLBuilder.load(Modeler.class, storageName, configuration);
-
-        instance.predict(trainingData);
-
-        ClassificationMetrics vm = new ClassificationMetrics(trainingData);
-
-        double expResult2 = 0.8;
-        assertEquals(expResult2, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH);
-
-        trainingData.close();
-        instance.close();
-        //instance = null;
-
-
-        instance = MLBuilder.load(Modeler.class, storageName, configuration);
-        
-        instance.predict(validationData);
-        
-        
-        
-        Map<Integer, Object> expResult = new HashMap<>();
-        Map<Integer, Object> result = new HashMap<>();
-        for(Map.Entry<Integer, Record> e : validationData.entries()) {
-            Integer rId = e.getKey();
-            Record r = e.getValue();
-            expResult.put(rId, r.getY());
-            result.put(rId, r.getYPredicted());
-        }
-        assertEquals(expResult, result);
-        
-        instance.delete();
-
-        validationData.close();
+    instance = MLBuilder.load(Modeler.class, storageName, configuration);
+    
+    instance.predict(trainingData);
+    
+    ClassificationMetrics vm = new ClassificationMetrics(trainingData);
+    
+    double expResult2 = 0.8;
+    assertEquals(expResult2, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH);
+    
+    trainingData.close();
+    instance.close();
+    
+    // Reload the instance for validation data prediction
+    instance = MLBuilder.load(Modeler.class, storageName, configuration);
+    instance.predict(validationData);
+    
+    Map<Integer, Object> expResult = new HashMap<>();
+    Map<Integer, Object> result = new HashMap<>();
+    for(Map.Entry<Integer, Record> e : validationData.entries()) {
+        Integer rId = e.getKey();
+        Record r = e.getValue();
+        expResult.put(rId, r.getY());
+        result.put(rId, r.getYPredicted());
     }
+    
+    assertEquals(expResult, result);
+    
+    instance.delete();
+    validationData.close();
+}

----------------------------------------------------------------
diff generated new test
--- 

+++ 

@@ -1,62 +1,72 @@

 @Test
-public void testTrainAndValidate() {
-    logger.info("testTrainAndValidate");
-    
-    Configuration configuration = Configuration.getConfiguration();
-    
-    Dataframe[] data = Datasets.carsNumeric(configuration);
-    Dataframe trainingData = data[0];
-    Dataframe validationData = data[1];
-    
-    String storageName = this.getClass().getSimpleName();
+    public void testTrainAndValidate() {
+        logger.info("testTrainAndValidate");
+        
+        Configuration configuration = Configuration.getConfiguration();
+        
+        Dataframe[] data = Datasets.carsNumeric(configuration);
+        Dataframe trainingData = data[0];
+        
+        Dataframe validationData = data[1];
+        
+        
+        String storageName = this.getClass().getSimpleName();
 
-    Modeler.TrainingParameters trainingParameters = new Modeler.TrainingParameters();
-    
-    // Model Configuration
-    MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters();
-    modelTrainingParameters.setMultiProbabilityWeighted(true);
-    trainingParameters.setModelerTrainingParameters(modelTrainingParameters);
+        Modeler.TrainingParameters trainingParameters = new Modeler.TrainingParameters();
+        
 
-    // Numerical scaling and categorical encoding configuration
-    trainingParameters.setNumericalScalerTrainingParameters(null);
-    trainingParameters.setCategoricalEncoderTrainingParameters(null);
+        //numerical scaling configuration
+        MinMaxScaler.TrainingParameters nsParams = new MinMaxScaler.TrainingParameters();
+        trainingParameters.setNumericalScalerTrainingParameters(nsParams);
 
-    // Feature selection configuration
-    trainingParameters.setFeatureSelectorTrainingParameters(null);
+        //categorical encoding configuration
+        CornerConstraintsEncoder.TrainingParameters ceParams = new CornerConstraintsEncoder.TrainingParameters();
+        trainingParameters.setCategoricalEncoderTrainingParameters(ceParams);
+        
+        //feature selection configuration
+        trainingParameters.setFeatureSelectorTrainingParameters(null);
 
-    Modeler instance = MLBuilder.create(trainingParameters, configuration);
-    instance.fit(trainingData);
-    instance.save(storageName);
+        //model Configuration
+        MultinomialNaiveBayes.TrainingParameters modelTrainingParameters = new MultinomialNaiveBayes.TrainingParameters();
+        modelTrainingParameters.setMultiProbabilityWeighted(true);
+        trainingParameters.setModelerTrainingParameters(modelTrainingParameters);
 
-    instance.close();
+        Modeler instance = MLBuilder.create(trainingParameters, configuration);
+        instance.fit(trainingData);
+        instance.save(storageName);
 
-    instance = MLBuilder.load(Modeler.class, storageName, configuration);
-    
-    instance.predict(trainingData);
-    
-    ClassificationMetrics vm = new ClassificationMetrics(trainingData);
-    
-    double expResult2 = 0.8;
-    assertEquals(expResult2, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH);
-    
-    trainingData.close();
-    instance.close();
-    
-    // Reload the instance for validation data prediction
-    instance = MLBuilder.load(Modeler.class, storageName, configuration);
-    instance.predict(validationData);
-    
-    Map<Integer, Object> expResult = new HashMap<>();
-    Map<Integer, Object> result = new HashMap<>();
-    for(Map.Entry<Integer, Record> e : validationData.entries()) {
-        Integer rId = e.getKey();
-        Record r = e.getValue();
-        expResult.put(rId, r.getY());
-        result.put(rId, r.getYPredicted());
+        instance.close();
+
+        instance = MLBuilder.load(Modeler.class, storageName, configuration);
+
+        instance.predict(trainingData);
+
+        ClassificationMetrics vm = new ClassificationMetrics(trainingData);
+
+        double expResult2 = 0.8;
+        assertEquals(expResult2, vm.getMacroF1(), Constants.DOUBLE_ACCURACY_HIGH);
+
+        trainingData.close();
+        instance.close();
+
+
+        instance = MLBuilder.load(Modeler.class, storageName, configuration);
+        
+        instance.predict(validationData);
+        
+        
+        
+        Map<Integer, Object> expResult = new HashMap<>();
+        Map<Integer, Object> result = new HashMap<>();
+        for(Map.Entry<Integer, Record> e : validationData.entries()) {
+            Integer rId = e.getKey();
+            Record r = e.getValue();
+            expResult.put(rId, r.getY());
+            result.put(rId, r.getYPredicted());
+        }
+        assertEquals(expResult, result);
+        
+        instance.delete();
+
+        validationData.close();
     }
-    
-    assertEquals(expResult, result);
-    
-    instance.delete();
-    validationData.close();
-}

--------------------------------------------------------------------------------------------------------------------------------
